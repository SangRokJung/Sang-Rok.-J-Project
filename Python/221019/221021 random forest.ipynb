{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40b6bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn import metrics\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0a2ab10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 데이터 전처리\n",
    "df_t = sns.load_dataset('titanic')\n",
    "\n",
    "# 불필요 컬럼 제거\n",
    "df_t.drop(columns=['class', 'alive', 'embark_town', 'who', 'adult_male', 'alone'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# 연령의 결측치 해결\n",
    "age_md = df_t.groupby(['pclass', 'sex']).age.agg(['median'])\n",
    "df_t.loc[(df_t['sex'] == 'male') & (df_t['pclass'] == 1) & (df_t.age.isna()), \"age\"] = age_md.loc[1, 'male'][0]\n",
    "df_t.loc[(df_t['sex'] == 'male') & (df_t['pclass'] == 2) & (df_t.age.isna()), \"age\"] = age_md.loc[2, 'male'][0]\n",
    "df_t.loc[(df_t['sex'] == 'male') & (df_t['pclass'] == 3) & (df_t.age.isna()), \"age\"] = age_md.loc[3, 'male'][0]\n",
    "df_t.loc[(df_t['sex'] == 'female') & (df_t['pclass'] == 1) & (df_t.age.isna()), \"age\"] = age_md.loc[1, 'female'][0]\n",
    "df_t.loc[(df_t['sex'] == 'female') & (df_t['pclass'] == 2) & (df_t.age.isna()), \"age\"] = age_md.loc[2, 'female'][0]\n",
    "df_t.loc[(df_t['sex'] == 'female') & (df_t['pclass'] == 3) & (df_t.age.isna()), \"age\"] = age_md.loc[3, 'female'][0]\n",
    "\n",
    "# embarked 결측치 해결\n",
    "df_t.embarked.fillna(df_t.embarked.unique()[0], inplace=True)\n",
    "\n",
    "# 연령층 별 컬럼 생성.\n",
    "df_t.loc[df_t.age >= 50, \"age_new\"] = \"old\"\n",
    "df_t.loc[(df_t.age < 50) & (df_t.age>=10), \"age_new\"] = \"young\"\n",
    "df_t.loc[df_t.age < 10, \"age_new\"] = \"baby\"\n",
    "\n",
    "# 인코딩\n",
    "# for column in ['sex', 'embarked', 'age_new'] :\n",
    "#     datas = df_t[column].unique()\n",
    "#     for i, d in enumerate(datas) :\n",
    "#         df_t[column].replace(d, i, inplace=True)\n",
    "\n",
    "# 인코딩\n",
    "og_columns = df_t.columns[(df_t.dtypes=='O')|(df_t.dtypes=='category')|(df_t.dtypes=='bool')]            \n",
    "for i in og_columns :\n",
    "    globals()[f'df1_{i}_encoder'] = LabelEncoder()\n",
    "    globals()[f'df1_{i}_encoder'].fit(df_t[i])\n",
    "    df_t[i] = globals()[f'df1_{i}_encoder'].transform(df_t[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X, Y 분리\n",
    "X = df_t.drop(columns='survived')\n",
    "y = df_t['survived']\n",
    "\n",
    "# test, train 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=12)\n",
    "\n",
    "# np.random.shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=1000) #ccp : 분기점\n",
    "rfc.fit(X_train, y_train)\n",
    "# predict이 필요한 이유 : 정답이 없는 경우가 있기 때문.\n",
    "dt_pred = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "# 새로운 타이타닉 데이터 전처리 \n",
    "\n",
    "df_test = pd.read_csv('./test.csv')\n",
    "\n",
    "# df_test.info()\n",
    "# Name, Sex, Ticket, Cabin, Embarked 해결 필요\n",
    "\n",
    "# 연령의 결측치 해결\n",
    "# fare 결측치 해결\n",
    "age_md = df_test.groupby(['Pclass', 'Sex']).Age.agg(['median'])\n",
    "fare_md = df_test.groupby(['Pclass', 'Sex']).Fare.agg(['median'])\n",
    "for i in ['male', 'female'] : \n",
    "    for y in range(1, 4) : \n",
    "        f\"df_test.loc[(df_test['Sex'] == '{i}') & (df_test['Pclass'] == {y}) & (df_test.Age.isna()), 'Age'] = age_md.loc[{y}, '{i}'][0]\"\n",
    "        f\"df_test.loc[(df_test['Sex'] == '{i}') & (df_test['Pclass'] == {y}) & (df_test.Fare.isna()), 'Fare'] = fare_md.loc[{y}, '{i}'][0]\"\n",
    "        \n",
    "\n",
    "# 결측치가 너무 많은 데이터, 컬럼 삭제\n",
    "df_test.drop(columns=['Cabin'], inplace=True)\n",
    "\n",
    "# age_new 생성\n",
    "df_test.loc[df_test.Age >= 50, \"age_new\"] = \"old\"\n",
    "df_test.loc[(df_test.Age < 50) & (df_test.Age>=10), \"age_new\"] = \"young\"\n",
    "df_test.loc[df_test.Age < 10, \"age_new\"] = \"baby\"\n",
    "\n",
    "# 필요 없는 데이터 제거\n",
    "df_test.drop(columns=['Name', 'Ticket', 'PassengerId', \"SibSp\", \"Parch\", 'Age', 'Embarked'], inplace=True)\n",
    "\n",
    "\n",
    "# 컬럼 소문자로 변경 \n",
    "l1 = []\n",
    "for i in list(df_test.columns):\n",
    "    l1.append(i.lower())\n",
    "df_test.set_axis(l1, axis='columns', inplace=True)\n",
    "\n",
    "# Index(['pclass', 'Sex', 'age', 'fare', 'embarked', 'predict survived'], dtype='object')\n",
    "# Labeling으로 문자형 데이터를 숫자형으로 변환\n",
    "for i in ['sex', 'age_new']:\n",
    "    globals()[f'df_test{i}_encoder'] = LabelEncoder()\n",
    "    globals()[f'df_test{i}_encoder'].fit(df_test[i])\n",
    "    df_test[i] = globals()[f'df_test{i}_encoder'].transform(df_test[i])\n",
    "\n",
    "# fare 결측치 해결    \n",
    "df_test['fare'].fillna(df_test['fare'].mean(), inplace=True)\n",
    "# df_test[df_test['fare'].isna() == True] \n",
    "\n",
    "# 학습 데이터 70%, 테스트 데이터 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "99d9f7e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Name'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [143]\u001b[0m, in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     50\u001b[0m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaster\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaster\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m df_train\u001b[38;5;241m=\u001b[39m\u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m df_train\u001b[38;5;241m=\u001b[39mdf_train\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicket\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# 연령의 결측치 해결\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# fare 결측치 해결\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4816\u001b[0m ):\n\u001b[1;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Name'] not found in axis\""
     ]
    }
   ],
   "source": [
    "### orginal data ###\n",
    "df_train = pd.read_csv(\"./titanic/train.csv\")\n",
    "\n",
    "df_train.drop(columns=[\"PassengerId\", \"Cabin\"], inplace=True)\n",
    "\n",
    "df_train[\"Embarked\"].fillna(df_train[\"Embarked\"].unique()[0], inplace=True)\n",
    "df_train['Name'] = df_train['Name'].str.split(', ').str[1].str.split('. ').str[0]\n",
    "\n",
    "df_train['Master']=(df_train['Name']=='Master')\n",
    "df_train=df_train.drop(columns='Name')\n",
    "df_train=df_train.drop(columns='Ticket')\n",
    "\n",
    "# age_new 컬럼 생성.\n",
    "df_train.loc[df_train.Age >= 50, \"age_new\"] = \"old\"\n",
    "df_train.loc[(df_train.Age < 50) & (df_train.Age>=10), \"age_new\"] = \"young\"\n",
    "df_train.loc[df_train.Age < 10, \"age_new\"] = \"baby\"\n",
    "\n",
    "# 인코딩\n",
    "og_columns = df_train.columns[(df_train.dtypes=='O')|(df_train.dtypes=='category')|(df_train.dtypes=='bool')]\n",
    "for i in og_columns : \n",
    "    globals()[f'df_train_{i}_encoder'] = LabelEncoder()\n",
    "    globals()[f'df_train_{i}_encoder'].fit(df_train[i])\n",
    "    df_train[i] = globals()[f'df_train_{i}_encoder'].transform(df_train[i])\n",
    "    \n",
    "# 연령의 결측치 해결\n",
    "Age_md = df_train.groupby(['Pclass', 'Sex']).Age.agg(['median'])\n",
    "df_train.loc[(df_train['Sex'] ==  0) & (df_train['Pclass'] == 1) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[1, 0][0]\n",
    "df_train.loc[(df_train['Sex'] == 0) & (df_train['Pclass'] == 2) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[2, 0][0]\n",
    "df_train.loc[(df_train['Sex'] == 0) & (df_train['Pclass'] == 3) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[3, 0][0]\n",
    "df_train.loc[(df_train['Sex'] == 1) & (df_train['Pclass'] == 1) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[1, 1][0]\n",
    "df_train.loc[(df_train['Sex'] == 1) & (df_train['Pclass'] == 2) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[2, 1][0]\n",
    "df_train.loc[(df_train['Sex'] == 1) & (df_train['Pclass'] == 3) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[3, 1][0]\n",
    "\n",
    "df_train[\"family\"] = df_train.SibSp + df_train.Parch\n",
    "df_train.drop(columns=[\"SibSp\", \"Parch\"], inplace=True)\n",
    "\n",
    "# X, Y , test, train 분리\n",
    "X = df_train.drop(columns='Survived')\n",
    "y = df_train['Survived']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=19)\n",
    "\n",
    "\n",
    "# 새로운 타이타닉 데이터 전처리 \n",
    "df_test = pd.read_csv('./test.csv')\n",
    "\n",
    "df_test.drop(columns=[\"PassengerId\", \"Cabin\"], inplace=True)\n",
    "df_test['Name'] = df_test['Name'].str.split(', ').str[1].str.split('. ').str[0]\n",
    "\n",
    "df_train['Master']=(df_test['Name']=='Master')\n",
    "df_train=df_train.drop(columns='Name')\n",
    "df_train=df_train.drop(columns='Ticket')\n",
    "\n",
    "# 연령의 결측치 해결\n",
    "# fare 결측치 해결\n",
    "age_md = df_test.groupby(['Pclass', 'Sex']).Age.agg(['mean'])\n",
    "df_test.loc[(df_test['Sex'] == 'male') & (df_test['Pclass'] == 1) & (df_test.Age.isna()), 'Age'] = age_md.loc[1, 'male'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'male') & (df_test['Pclass'] == 2) & (df_test.Age.isna()), 'Age'] = age_md.loc[2, 'male'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'male') & (df_test['Pclass'] == 3) & (df_test.Age.isna()), 'Age'] = age_md.loc[3, 'male'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'female') & (df_test['Pclass'] == 1) & (df_test.Age.isna()), 'Age'] = age_md.loc[1, 'female'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'female') & (df_test['Pclass'] == 2) & (df_test.Age.isna()), 'Age'] = age_md.loc[2, 'female'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'female') & (df_test['Pclass'] == 3) & (df_test.Age.isna()), 'Age'] = age_md.loc[3, 'female'][0]\n",
    "df_test.Fare.fillna(df_test[\"Fare\"].mean(), inplace=True)\n",
    "\n",
    "# age_new 생성\n",
    "df_test.loc[df_test.Age >= 50, \"age_new\"] = \"old\"\n",
    "df_test.loc[(df_test.Age < 50) & (df_test.Age>=10), \"age_new\"] = \"young\"\n",
    "df_test.loc[df_test.Age < 10, \"age_new\"] = \"baby\"\n",
    "\n",
    "df_test[\"family\"] = df_test.SibSp + df_test.Parch\n",
    "df_test.drop(columns=[\"SibSp\", \"Parch\"], inplace=True)\n",
    "\n",
    "og_columns = df_test.columns[(df_test.dtypes=='O')|(df_test.dtypes=='category')|(df_test.dtypes=='bool')]\n",
    "for i in og_columns : \n",
    "    globals()[f'df_test{i}_encoder'] = LabelEncoder()\n",
    "    globals()[f'df_test{i}_encoder'].fit(df_test[i])\n",
    "    df_test[i] = globals()[f'df_test{i}_encoder'].transform(df_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fe06b4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Name', ylabel='count'>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=df_train, x='Name', hue='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 타이타닉 데이터 생존 여부 예측\n",
    "pred_result = rfc.predict(df_test)\n",
    "pred_result_2 =  df_tsurvived_encoder.inverse_transform(pred_result)\n",
    "df_test['survived'] = pred_result_2\n",
    "\n",
    "# 파일 저장\n",
    "tit = pd.read_csv('./test.csv')\n",
    "tit.drop(list(tit.columns)[1:], axis = 1, inplace=True)\n",
    "tit['Survived'] = df_test['survived']\n",
    "tit.set_index('PassengerId', inplace=True)\n",
    "tit.to_csv('tit_test_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "078a5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nRandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=10000, n_jobs=-1) #ccp : 분기점\n",
    "rfc.fit(X_train, y_train)\n",
    "dt_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2349e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtclf = DecisionTreeClassifier(max_depth=5) #ccp : 분기점\n",
    "dtclf.fit(X_train, y_train)\n",
    "dt_pred = dtclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08645ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44 11]\n",
      " [13 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79        55\n",
      "           1       0.67      0.63      0.65        35\n",
      "\n",
      "    accuracy                           0.73        90\n",
      "   macro avg       0.72      0.71      0.72        90\n",
      "weighted avg       0.73      0.73      0.73        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_hat = knn.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "knn_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(knn_matrix)\n",
    "\n",
    "knn_report = metrics.classification_report(y_test, y_hat)\n",
    "print(knn_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba3047ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred) :\n",
    "    print(\"-\" * 5)\n",
    "    print(\"오차 행렬\\n\",confusion_matrix(y_test, pred))\n",
    "    print(\"정확도(accuracy) : %.2f\" %accuracy_score(y_test, pred))\n",
    "    print(\"정밀도(precision) : %.2f\" %precision_score(y_test, pred))\n",
    "    print(\"재현율(recall) : %.2f\" %recall_score(y_test, pred))\n",
    "    print(\"f1 Score : %.2f\" %f1_score(y_test, pred))\n",
    "    print(\"AUC : %.2f\" % roc_auc_score(y_test, pred))\n",
    "    print(\"-\" * 5)\n",
    "    return accuracy_score(y_test, pred), precision_score(y_test, pred),recall_score(y_test, pred), f1_score(y_test, pred), roc_auc_score(y_test, pred) \n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "def get_eval_by_threshold(y_test, pred_proba):\n",
    "    ts_accuracy = []\n",
    "    ts_precision = []\n",
    "    ts_recall = []\n",
    "    ts_datas = {}\n",
    "    f1_list = []\n",
    "    auc_list= []\n",
    "    for custom_threshold in range(1, 11) :\n",
    "        tt_binarizer = Binarizer(threshold=custom_threshold * 0.1)\n",
    "        custom_predict = tt_binarizer.fit_transform(pred_proba)[:, 1]\n",
    "        accuracy  = accuracy_score(y_test, custom_predict)\n",
    "        recall    = recall_score(y_test, custom_predict)\n",
    "        precision = precision_score(y_test, custom_predict)\n",
    "        f1 = f1_score(y_test, custom_predict)\n",
    "        auc = roc_auc_score(y_test, custom_predict)\n",
    "        \n",
    "        ts_accuracy.append(accuracy)\n",
    "        ts_precision.append(precision)\n",
    "        ts_recall.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        auc_list.append(auc)\n",
    "        \n",
    "    ts_datas['thresholds'] = [i * 0.1 for i in range(1, 11)]\n",
    "    ts_datas['accuracy'] = ts_accuracy\n",
    "    ts_datas['precision'] = ts_precision\n",
    "    ts_datas['recall'] = ts_recall\n",
    "    ts_datas['f1_score'] = f1_list\n",
    "    ts_datas['auc'] = auc_list\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    pd.DataFrame(ts_datas).set_index('thresholds').plot()\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d648a629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtclf = DecisionTreeClassifier() # option : max_depth=4, ccp_alpha=0.01\n",
    "dtclf.fit(X_train, y_train)\n",
    "pred_proba = dtclf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d78200c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  5]\n",
      " [25 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.91      0.77        55\n",
      "           1       0.67      0.29      0.40        35\n",
      "\n",
      "    accuracy                           0.67        90\n",
      "   macro avg       0.67      0.60      0.58        90\n",
      "weighted avg       0.67      0.67      0.63        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "svm_clf = SVC(kernel = 'rbf')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_hat = svm_clf.predict(X_test)\n",
    "\n",
    "svm_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(svm_matrix)\n",
    "\n",
    "svm_report = metrics.classification_report(y_test, y_hat)\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47897e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForestClassifier(n_estimators=10000, n_jobs=-1) \n",
      "-----\n",
      "오차 행렬\n",
      " [[54  5]\n",
      " [ 6 25]]\n",
      "정확도(accuracy) : 0.88\n",
      "정밀도(precision) : 0.83\n",
      "재현율(recall) : 0.81\n",
      "f1 Score : 0.82\n",
      "AUC : 0.86\n",
      "-----\n",
      "\n",
      "RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, criterion='entropy', max_features=None,)\n",
      "-----\n",
      "오차 행렬\n",
      " [[58  1]\n",
      " [12 19]]\n",
      "정확도(accuracy) : 0.86\n",
      "정밀도(precision) : 0.95\n",
      "재현율(recall) : 0.61\n",
      "f1 Score : 0.75\n",
      "AUC : 0.80\n",
      "-----\n",
      "\n",
      "ExtraTreesClassifier\n",
      "-----\n",
      "오차 행렬\n",
      " [[50  9]\n",
      " [ 9 22]]\n",
      "정확도(accuracy) : 0.80\n",
      "정밀도(precision) : 0.71\n",
      "재현율(recall) : 0.71\n",
      "f1 Score : 0.71\n",
      "AUC : 0.78\n",
      "-----\n",
      "\n",
      "ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, bootstrap=True, random_state=10, max_samples=1.0)\n",
      "-----\n",
      "오차 행렬\n",
      " [[58  1]\n",
      " [ 9 22]]\n",
      "정확도(accuracy) : 0.89\n",
      "정밀도(precision) : 0.96\n",
      "재현율(recall) : 0.71\n",
      "f1 Score : 0.81\n",
      "AUC : 0.85\n",
      "-----\n",
      "\n",
      "DecisionTreeClassifier(max_depth=5)\n",
      "-----\n",
      "오차 행렬\n",
      " [[57  2]\n",
      " [12 19]]\n",
      "정확도(accuracy) : 0.84\n",
      "정밀도(precision) : 0.90\n",
      "재현율(recall) : 0.61\n",
      "f1 Score : 0.73\n",
      "AUC : 0.79\n",
      "-----\n",
      "\n",
      "BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, max_samples=1.0, bootstrap=False, n_jobs=-1, bootstrap_features=True, max_features=0.5, oob_score=False)\n",
      "-----\n",
      "오차 행렬\n",
      " [[56  3]\n",
      " [10 21]]\n",
      "정확도(accuracy) : 0.86\n",
      "정밀도(precision) : 0.88\n",
      "재현율(recall) : 0.68\n",
      "f1 Score : 0.76\n",
      "AUC : 0.81\n",
      "-----\n",
      "\n",
      "DecisionTreeClassifier\n",
      "-----\n",
      "오차 행렬\n",
      " [[49 10]\n",
      " [ 9 22]]\n",
      "정확도(accuracy) : 0.79\n",
      "정밀도(precision) : 0.69\n",
      "재현율(recall) : 0.71\n",
      "f1 Score : 0.70\n",
      "AUC : 0.77\n",
      "-----\n",
      "\n",
      "ExtraTreeClassifier\n",
      "-----\n",
      "오차 행렬\n",
      " [[50  9]\n",
      " [ 8 23]]\n",
      "정확도(accuracy) : 0.81\n",
      "정밀도(precision) : 0.72\n",
      "재현율(recall) : 0.74\n",
      "f1 Score : 0.73\n",
      "AUC : 0.79\n",
      "-----\n",
      "\n",
      "KNeighborsClassifier\n",
      "-----\n",
      "오차 행렬\n",
      " [[49 10]\n",
      " [13 18]]\n",
      "정확도(accuracy) : 0.74\n",
      "정밀도(precision) : 0.64\n",
      "재현율(recall) : 0.58\n",
      "f1 Score : 0.61\n",
      "AUC : 0.71\n",
      "-----\n",
      "\n",
      "SVC\n",
      "-----\n",
      "오차 행렬\n",
      " [[49 10]\n",
      " [13 18]]\n",
      "정확도(accuracy) : 0.74\n",
      "정밀도(precision) : 0.64\n",
      "재현율(recall) : 0.58\n",
      "f1 Score : 0.61\n",
      "AUC : 0.71\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7444444444444445,\n",
       " 0.6428571428571429,\n",
       " 0.5806451612903226,\n",
       " 0.6101694915254238,\n",
       " 0.7055768179332969)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nRandomForestClassifier(n_estimators=10000, n_jobs=-1) \")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=10000, n_jobs=-1) \n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_dt_pred = rfc.predict(X_test)\n",
    "get_clf_eval(y_test, rfc_dt_pred)\n",
    "\n",
    "print(\"\\nRandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, criterion='entropy', max_features=None,)\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, \n",
    "                                 criterion='entropy', max_features=None,)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "rnd_clf_dt_pred = rnd_clf.predict(X_test)\n",
    "get_clf_eval(y_test, rnd_clf_dt_pred)\n",
    "\n",
    "\n",
    "print(\"\\nExtraTreesClassifier\")\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etsc = ExtraTreesClassifier()\n",
    "etsc.fit(X_train, y_train)\n",
    "etsc_dt_pred = etsc.predict(X_test)\n",
    "get_clf_eval(y_test, etsc_dt_pred)\n",
    "\n",
    "\n",
    "print(\"\\nExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, bootstrap=True, random_state=10, max_samples=1.0)\")\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "et_clf = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, \n",
    "                              bootstrap=True, random_state=10, max_samples=1.0)\n",
    "et_clf.fit(X_train, y_train)\n",
    "et_clf_dt_pred = et_clf.predict(X_test)\n",
    "get_clf_eval(y_test, et_clf_dt_pred)\n",
    "\n",
    "\n",
    "print(\"\\nDecisionTreeClassifier(max_depth=5)\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtclf = DecisionTreeClassifier(max_depth=5) \n",
    "dtclf.fit(X_train, y_train)\n",
    "dtclf_dt_pred = dtclf.predict(X_test)\n",
    "get_clf_eval(y_test, dtclf_dt_pred)\n",
    "\n",
    "print(\"\\nBaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, max_samples=1.0, bootstrap=False, n_jobs=-1, bootstrap_features=True, max_features=0.5, oob_score=False)\")\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, \n",
    "                            max_samples=1.0, bootstrap=False, n_jobs=-1,\n",
    "                            bootstrap_features=True, max_features=0.5, oob_score=False)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf_dt_pred = bag_clf.predict(X_test)\n",
    "get_clf_eval(y_test, bag_clf_dt_pred)\n",
    "\n",
    "print(\"\\nDecisionTreeClassifier\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtclf = DecisionTreeClassifier() \n",
    "dtclf.fit(X_train, y_train)\n",
    "dtclf_dt_pred = dtclf.predict(X_test)\n",
    "get_clf_eval(y_test, dtclf_dt_pred)\n",
    "\n",
    "print(\"\\nExtraTreeClassifier\")\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "etc = ExtraTreeClassifier() \n",
    "etc.fit(X_train, y_train)\n",
    "etc_dt_pred = etc.predict(X_test)\n",
    "get_clf_eval(y_test, etc_dt_pred)\n",
    "\n",
    "print(\"\\nKNeighborsClassifier\")\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "kncf = KNeighborsClassifier()\n",
    "kncf.fit(X_train, y_train)\n",
    "kncf_dt_pred = kncf.predict(X_test)\n",
    "get_clf_eval(y_test, kncf_dt_pred)\n",
    "\n",
    "print(\"\\nSVC\")\n",
    "from sklearn.svm import SVC \n",
    "svc = KNeighborsClassifier()\n",
    "svc.fit(X_train, y_train)\n",
    "svc_dt_pred = svc.predict(X_test)\n",
    "get_clf_eval(y_test, svc_dt_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e23363c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etsc = ExtraTreesClassifier()\n",
    "etsc.fit(X, y)\n",
    "etsc_dt_pred = etsc.predict(df_test)\n",
    "df_test['survived'] = etsc_dt_pred\n",
    "\n",
    "# 파일 저장\n",
    "tit = pd.read_csv('./test.csv')\n",
    "tit.drop(list(tit.columns)[1:], axis = 1, inplace=True)\n",
    "tit['Survived'] = df_test['survived']\n",
    "tit.set_index('PassengerId', inplace=True)\n",
    "tit.to_csv('tit_test_etsc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11947526",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, \n",
    "                                 criterion='entropy', max_features=None,)\n",
    "et_clf = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, \n",
    "                              bootstrap=True, random_state=10, max_samples=1.0)\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, \n",
    "                            max_samples=1.0, bootstrap=False, n_jobs=-1,\n",
    "                            bootstrap_features=True, max_features=0.5, oob_score=False)\n",
    "voting_model = VotingClassifier(estimators=[('RandomForestClassifier', rnd_clf), ('BaggingClassifier', bag_clf),\n",
    "                                            ('ExtraTreesClassifier', et_clf)], voting='soft', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a57d801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting kaggle\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_model = VotingClassifier(estimators=[('RandomForestClassifier', rnd_clf), ('BaggingClassifier', bag_clf),\n",
    "                                            ('ExtraTreesClassifier', et_clf)], voting='soft', n_jobs=-1)\n",
    "voting_model.fit(X, y)\n",
    "voting_model_dt_pred = voting_model.predict(df_test)\n",
    "df_test['survived'] = voting_model_dt_pred\n",
    "\n",
    "# 파일 저장\n",
    "tit = pd.read_csv('./test.csv')\n",
    "tit.drop(list(tit.columns)[1:], axis = 1, inplace=True)\n",
    "tit['Survived'] = df_test['survived']\n",
    "tit.set_index('PassengerId', inplace=True)\n",
    "tit.to_csv('tit_test_voting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5e40c2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>age_new</th>\n",
       "      <th>family</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24.525104</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24.525104</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24.525104</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age      Fare  age_new  family  survived\n",
       "0         3    1  34.500000    7.8292        2       0         0\n",
       "1         3    0  47.000000    7.0000        2       1         0\n",
       "2         2    1  62.000000    9.6875        1       0         1\n",
       "3         3    1  27.000000    8.6625        2       0         0\n",
       "4         3    0  22.000000   12.2875        2       2         1\n",
       "..      ...  ...        ...       ...      ...     ...       ...\n",
       "413       3    1  24.525104    8.0500        2       0         0\n",
       "414       1    0  39.000000  108.9000        2       0         1\n",
       "415       3    1  38.500000    7.2500        2       0         0\n",
       "416       3    1  24.525104    8.0500        2       0         0\n",
       "417       3    1  24.525104   22.3583        2       2         0\n",
       "\n",
       "[418 rows x 7 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "678ab512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "-----\n",
      "오차 행렬\n",
      " [[57  2]\n",
      " [ 8 23]]\n",
      "정확도(accuracy) : 0.89\n",
      "정밀도(precision) : 0.92\n",
      "재현율(recall) : 0.74\n",
      "f1 Score : 0.82\n",
      "AUC : 0.85\n",
      "-----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m : [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m)], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m : [i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.01\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m)]}\n\u001b[1;32m     23\u001b[0m grid_cv \u001b[38;5;241m=\u001b[39m GridSearchCV(gbc, param_grid\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mgrid_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m gcv \u001b[38;5;241m=\u001b[39m grid_cv\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m최적 하이퍼 파라미터:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, gcv)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:586\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:663\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    656\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[1;32m    657\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    658\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    659\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:249\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    246\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(X, residual, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_terminal_regions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# add tree to ensemble\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[i, k] \u001b[38;5;241m=\u001b[39m tree\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb_losses.py:121\u001b[0m, in \u001b[0;36mLossFunction.update_terminal_regions\u001b[0;34m(self, tree, X, y, residual, raw_predictions, sample_weight, sample_mask, learning_rate, k)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# update each leaf (= perform line search)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m leaf \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(tree\u001b[38;5;241m.\u001b[39mchildren_left \u001b[38;5;241m==\u001b[39m TREE_LEAF)[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_terminal_region\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmasked_terminal_regions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# update predictions (both in-bag and out-of-bag)\u001b[39;00m\n\u001b[1;32m    133\u001b[0m raw_predictions[:, k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m tree\u001b[38;5;241m.\u001b[39mvalue[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtake(\n\u001b[1;32m    134\u001b[0m     terminal_regions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    135\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb_losses.py:724\u001b[0m, in \u001b[0;36mBinomialDeviance._update_terminal_region\u001b[0;34m(self, tree, terminal_regions, leaf, X, y, residual, raw_predictions, sample_weight)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_terminal_region\u001b[39m(\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    707\u001b[0m     tree,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    714\u001b[0m     sample_weight,\n\u001b[1;32m    715\u001b[0m ):\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;124;03m\"\"\"Make a single Newton-Raphson step.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    our node estimate is given by:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    we take advantage that: y - prob = residual\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 724\u001b[0m     terminal_region \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mterminal_regions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleaf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    725\u001b[0m     residual \u001b[38;5;241m=\u001b[39m residual\u001b[38;5;241m.\u001b[39mtake(terminal_region, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    726\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mtake(terminal_region, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "GBM은 경사 하강법(Gradient Descent)를 이용해 가중치 업데이트를 수행하는 기법이다. \n",
    "GBM이 일반적으로 랜덤포레스트보다 성능이 뛰어나기는 하지만, 수행 시간이 오래 걸린다는 단점이 있다.\n",
    "\n",
    "loss : 경사 하강법에서 사용할 비용함수 지정 (디폴트는 deviance)\n",
    "learning_rate : 약한 학습기가 순차적으로 오류 값을 보정해 나가는 데 적용하는 계수로 0 ~ 1 값 지정 가능 (디폴트는 0.1)\n",
    "너무 작은 값 지정 -> 예측 성능은 높아질 수 있지만 수행 시간이 오래 걸릴 수 있고, 반복이 완료되어도 최소오류값을 찾지 못할 수 있음\n",
    "너무 큰 값 지정 -> 빠른 수행은 가능하지만 최소오류값을 못찾고 지나쳐 예측 성능이 저하될 수 있음\n",
    "n_estimators : 약한 학습기의 개수 (디폴트는 100)\n",
    "개수가 많을수록 예측 성능은 높아질 수 있지만 수행 시간이 오래 걸림\n",
    "subsample : 학습에 사용하는 데이터의 샘플링 비율로 0 ~ 1 값 지정 가능 (디폴트는 1, 즉 전체 학습 데이터 기반)\n",
    "'''\n",
    "\n",
    "print(\"GradientBoostingClassifier\")\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "gbc_dt_pred = gbc.predict(X_test)\n",
    "get_clf_eval(y_test, gbc_dt_pred)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'n_estimators' : [i for i in range(100, 200)], 'learning_rate' : [i * 0.01 for i in range(5, 10)]}\n",
    "grid_cv = GridSearchCV(gbc, param_grid=params)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "gcv = grid_cv.best_params_\n",
    "print('\\n최적 하이퍼 파라미터:\\n', gcv)\n",
    "print('최고 예측 정확도: {0:.4f}\\n'.format(grid_cv.best_score_))\n",
    "\n",
    "# new_pred = grid_cv.best_estimator_.predict(X_test)\n",
    "# get_clf_eval(y_test, new_pred)\n",
    "\n",
    "\n",
    "print(\"VotingClassifier\")\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_model = VotingClassifier(estimators=[('RandomForestClassifier', rnd_clf), ('BaggingClassifier', bag_clf),\n",
    "                                            ('ExtraTreesClassifier', et_clf)], voting='soft', n_jobs=-1)\n",
    "voting_model.fit(X_train, y_train)\n",
    "voting_model_dt_pred = voting_model.predict(X_test)\n",
    "get_clf_eval(y_test, voting_model_dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf865465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "오차 행렬\n",
      " [[57  2]\n",
      " [10 21]]\n",
      "정확도(accuracy) : 0.87\n",
      "정밀도(precision) : 0.91\n",
      "재현율(recall) : 0.68\n",
      "f1 Score : 0.78\n",
      "AUC : 0.82\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8666666666666667,\n",
       " 0.9130434782608695,\n",
       " 0.6774193548387096,\n",
       " 0.7777777777777777,\n",
       " 0.8217605248769819)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'ccp_alpha': 0.011001332269966666,\n",
    "         'learning_rate': 0.1,\n",
    "         'loss': 'exponential',\n",
    "         'max_depth': 8,\n",
    "         'max_features': 'log2',\n",
    "         'min_impurity_decrease': 0.8671820004771132,\n",
    "         'min_samples_leaf': 28,\n",
    "         'min_samples_split': 0.32582763423323347,\n",
    "         'n_estimators': 300}\n",
    "\n",
    "gbc = GradientBoostingClassifier(**param)\n",
    "gbc.fit(X_train, y_train)\n",
    "gbc_dt_pred = gbc.predict(X_test)\n",
    "get_clf_eval(y_test, gbc_dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d1160504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm 교차검증: 0.818\n",
      "gbm 예측점수: 0.9\n"
     ]
    }
   ],
   "source": [
    "gbm_clf = GradientBoostingClassifier()\n",
    "\n",
    "gbm_results = cross_val_score(gbm_clf, X_train, y_train, scoring='accuracy', cv=10, n_jobs=4)\n",
    "print('gbm 교차검증:', round(np.mean(gbm_results), 3))\n",
    "\n",
    "gbm_clf.fit(X_train, y_train)\n",
    "print('gbm 예측점수:', round(np.mean(gbm_clf.score(X_test, y_test)), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b1e26d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                   | 0/500 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: __init__() got an unexpected keyword argument 'loss'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                   | 0/500 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [107]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m algorithm\u001b[38;5;241m=\u001b[39mtpe\u001b[38;5;241m.\u001b[39msuggest\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# implement Hyperopt\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgbm_objective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                   \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m ext_params \u001b[38;5;241m=\u001b[39m space_eval(search_space, best_params)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Input \u001b[0;32mIn [107]\u001b[0m, in \u001b[0;36mgbm_objective\u001b[0;34m(search_space)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgbm_objective\u001b[39m(search_space):\n\u001b[0;32m----> 5\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mExtraTreesClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'loss'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "\n",
    "def gbm_objective(search_space):\n",
    "    model = ExtraTreesClassifier(**search_space)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "\n",
    "# new search space\n",
    "search_space={'loss':hp.choice('loss', ['deviance', 'exponential']),\n",
    "              'max_depth':hp.choice('max_depth', range(2, 10)),\n",
    "              'min_samples_split':hp.uniform('min_samples_split', 0.1, 1),\n",
    "              'min_samples_leaf':hp.choice('min_samples_leaf', range(1, 30)),\n",
    "              'max_features':hp.choice('max_features', [None, 'sqrt', 'log2']),\n",
    "              'min_impurity_decrease':hp.uniform('min_impurity_decrease', 0.1, 1),\n",
    "              'ccp_alpha':hp.uniform('ccp_alpha', 0.01, 1),\n",
    "              'n_estimators':hp.choice('n_estimators', [100, 200, 300, 400, 500,1000])}\n",
    "\n",
    "# set the hyperparam tuning algorithm\n",
    "algorithm=tpe.suggest\n",
    "# implement Hyperopt\n",
    "best_params = fmin(fn=gbm_objective,\n",
    "                   space=search_space,\n",
    "                   algo=algorithm,\n",
    "                   max_evals=500)\n",
    "\n",
    "ext_params = space_eval(search_space, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c92412d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "오차 행렬\n",
      " [[57  2]\n",
      " [10 21]]\n",
      "정확도(accuracy) : 0.87\n",
      "정밀도(precision) : 0.91\n",
      "재현율(recall) : 0.68\n",
      "f1 Score : 0.78\n",
      "AUC : 0.82\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.01086648614691996,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'exponential',\n",
       " 'max_depth': 9,\n",
       " 'max_features': 'log2',\n",
       " 'min_impurity_decrease': 0.6528832299710262,\n",
       " 'min_samples_leaf': 19,\n",
       " 'min_samples_split': 0.10044367346597183,\n",
       " 'n_estimators': 400}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etsc = ExtraTreesClassifier()\n",
    "etsc.fit(X, y)\n",
    "etsc_dt_pred = etsc.predict(df_test)\n",
    "df_test['survived'] = etsc_dt_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "11e9a273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "오차 행렬\n",
      " [[57  2]\n",
      " [ 8 23]]\n",
      "정확도(accuracy) : 0.89\n",
      "정밀도(precision) : 0.92\n",
      "재현율(recall) : 0.74\n",
      "f1 Score : 0.82\n",
      "AUC : 0.85\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8888888888888888,\n",
       " 0.92,\n",
       " 0.7419354838709677,\n",
       " 0.8214285714285714,\n",
       " 0.854018589393111)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gbm_clf = GradientBoostingClassifier(**gb_params)\n",
    "best_gbm_clf.fit(X_train, y_train)\n",
    "best_gbm_clf_pred = best_gbm_clf.predict(X_test)\n",
    "get_clf_eval(y_test, gbc_dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7e28084",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbm_clf = GradientBoostingClassifier(**params1)\n",
    "best_gbm_clf.fit(X, y)\n",
    "best_gbm_clf_pred = best_gbm_clf.predict(df_test)\n",
    "df_test['survived'] = best_gbm_clf_pred\n",
    "\n",
    "# 파일 저장\n",
    "tit = pd.read_csv('./test.csv')\n",
    "tit.drop(list(tit.columns)[1:], axis = 1, inplace=True)\n",
    "tit['Survived'] = df_test['survived']\n",
    "tit.set_index('PassengerId', inplace=True)\n",
    "tit.to_csv('tit_test_gbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a66a7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58efc3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "db6e9afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  0%|                                   | 0/500 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  0%|        | 1/500 [00:00<03:33,  2.33trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  0%|        | 2/500 [00:00<03:24,  2.44trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  1%|        | 4/500 [00:01<02:54,  2.84trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  1%|        | 6/500 [00:01<02:13,  3.71trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  1%|        | 6/500 [00:01<02:13,  3.71trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  1%|        | 7/500 [00:02<02:23,  3.45trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  2%|▏       | 9/500 [00:02<02:04,  3.94trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  2%|▏       | 9/500 [00:02<02:04,  3.94trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  2%|▏      | 10/500 [00:02<02:19,  3.52trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  2%|▏      | 11/500 [00:03<02:26,  3.33trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  3%|▏      | 13/500 [00:03<02:00,  4.06trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  3%|▏      | 14/500 [00:03<01:53,  4.29trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  3%|▏      | 15/500 [00:04<01:52,  4.29trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  3%|▏      | 17/500 [00:04<02:14,  3.59trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  4%|▎      | 18/500 [00:04<01:38,  4.89trial/s, best loss: -0.8888888888888888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  4%|▉                     | 20/500 [00:05<02:06,  3.80trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  4%|▉                     | 22/500 [00:05<01:48,  4.39trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  4%|▉                     | 22/500 [00:05<01:48,  4.39trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  5%|█                     | 24/500 [00:06<01:43,  4.61trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  5%|█▏                    | 26/500 [00:06<01:46,  4.43trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  6%|█▏                    | 28/500 [00:07<01:33,  5.04trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  6%|█▎                    | 30/500 [00:07<01:22,  5.70trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  6%|█▍                    | 32/500 [00:08<01:48,  4.32trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  7%|█▍                    | 33/500 [00:08<01:37,  4.81trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  7%|█▌                    | 35/500 [00:09<02:31,  3.08trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  7%|█▌                    | 36/500 [00:09<02:09,  3.57trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  8%|█▋                    | 38/500 [00:09<01:40,  4.59trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  8%|█▊                    | 40/500 [00:10<02:36,  2.95trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  8%|█▊                    | 41/500 [00:11<02:24,  3.18trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  9%|█▉                    | 43/500 [00:11<01:54,  3.99trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  9%|█▉                    | 44/500 [00:11<01:45,  4.34trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  9%|██                    | 46/500 [00:12<01:33,  4.86trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 10%|██                    | 48/500 [00:12<01:18,  5.77trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 10%|██▏                   | 49/500 [00:12<01:13,  6.13trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 10%|██▏                   | 51/500 [00:12<01:15,  5.95trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 10%|██▎                   | 52/500 [00:13<01:32,  4.82trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 11%|██▍                   | 54/500 [00:13<01:46,  4.20trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 11%|██▍                   | 55/500 [00:13<01:47,  4.16trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 11%|██▍                   | 56/500 [00:14<02:22,  3.12trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 12%|██▌                   | 58/500 [00:14<02:06,  3.48trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 12%|██▌                   | 59/500 [00:15<01:42,  4.32trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 12%|██▋                   | 60/500 [00:15<02:10,  3.36trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:53] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 12%|██▋                   | 62/500 [00:16<01:59,  3.66trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:53] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:53] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 13%|██▊                   | 64/500 [00:16<01:42,  4.26trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 13%|██▉                   | 66/500 [00:17<02:08,  3.37trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 13%|██▉                   | 67/500 [00:17<02:10,  3.32trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 14%|██▉                   | 68/500 [00:17<02:13,  3.23trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 14%|███                   | 69/500 [00:18<02:17,  3.13trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 14%|███                   | 71/500 [00:18<01:49,  3.93trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 14%|███▏                  | 72/500 [00:18<01:38,  4.36trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 15%|███▎                  | 74/500 [00:19<01:44,  4.07trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 15%|███▎                  | 76/500 [00:19<01:28,  4.81trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 15%|███▍                  | 77/500 [00:19<01:18,  5.37trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 16%|███▍                  | 79/500 [00:20<01:32,  4.55trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 16%|███▌                  | 81/500 [00:20<01:10,  5.93trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 17%|███▋                  | 83/500 [00:20<01:05,  6.33trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 17%|███▋                  | 84/500 [00:21<01:09,  5.99trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 17%|███▊                  | 86/500 [00:21<01:54,  3.61trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 17%|███▊                  | 86/500 [00:21<01:54,  3.61trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 18%|███▊                  | 88/500 [00:22<01:36,  4.26trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:18:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:18:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 18%|███▉                  | 90/500 [00:22<01:20,  5.11trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 18%|████                  | 92/500 [00:23<01:30,  4.52trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 19%|████▏                 | 94/500 [00:23<01:33,  4.36trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 19%|████▏                 | 96/500 [00:24<01:38,  4.11trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 19%|████▎                 | 97/500 [00:24<01:26,  4.65trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 20%|████▎                 | 98/500 [00:24<01:49,  3.68trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 20%|████▎                 | 99/500 [00:25<01:44,  3.84trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 20%|████▏                | 100/500 [00:25<01:54,  3.49trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 20%|████▎                | 102/500 [00:25<01:38,  4.04trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      " 21%|████▎                | 104/500 [00:26<01:23,  4.72trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 21%|████▍                | 106/500 [00:26<01:10,  5.62trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 22%|████▌                | 108/500 [00:26<01:01,  6.33trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 22%|████▌                | 109/500 [00:26<01:03,  6.14trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 22%|████▋                | 111/500 [00:27<01:16,  5.06trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 23%|████▊                | 114/500 [00:27<01:11,  5.39trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 23%|████▊                | 115/500 [00:28<01:13,  5.26trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 23%|████▉                | 117/500 [00:28<01:28,  4.32trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 24%|████▉                | 119/500 [00:29<01:19,  4.77trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 24%|█████                | 120/500 [00:29<01:16,  4.99trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 24%|█████                | 121/500 [00:29<01:35,  3.98trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 25%|█████▏               | 123/500 [00:30<01:33,  4.02trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 25%|█████▎               | 125/500 [00:30<01:41,  3.70trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 25%|█████▎               | 126/500 [00:31<01:32,  4.05trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 26%|█████▍               | 128/500 [00:31<01:17,  4.80trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 26%|█████▍               | 129/500 [00:31<01:15,  4.91trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 26%|█████▌               | 131/500 [00:32<01:26,  4.28trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:10] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 27%|█████▌               | 133/500 [00:33<02:37,  2.33trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:10] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:10] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 27%|█████▋               | 134/500 [00:33<02:10,  2.80trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:10] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 27%|█████▋               | 136/500 [00:34<01:34,  3.85trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 27%|█████▊               | 137/500 [00:34<02:02,  2.97trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 28%|█████▊               | 138/500 [00:35<02:24,  2.50trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 28%|█████▉               | 140/500 [00:36<02:43,  2.21trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 28%|█████▉               | 140/500 [00:36<02:43,  2.21trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 28%|█████▉               | 142/500 [00:37<02:17,  2.61trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 29%|██████               | 144/500 [00:37<01:55,  3.08trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 29%|██████▏              | 146/500 [00:37<01:24,  4.20trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 30%|██████▏              | 148/500 [00:38<01:08,  5.10trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 30%|██████▎              | 150/500 [00:38<01:09,  5.06trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 30%|██████▍              | 152/500 [00:38<01:01,  5.64trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 31%|██████▍              | 154/500 [00:39<01:01,  5.60trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 31%|██████▌              | 156/500 [00:39<00:55,  6.19trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 32%|██████▋              | 158/500 [00:39<00:56,  6.09trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 32%|██████▋              | 160/500 [00:40<00:57,  5.93trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 32%|██████▊              | 162/500 [00:40<00:53,  6.28trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 33%|██████▊              | 163/500 [00:40<00:51,  6.48trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 33%|██████▉              | 165/500 [00:41<01:37,  3.42trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 33%|██████▉              | 166/500 [00:41<01:20,  4.14trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 34%|███████              | 168/500 [00:42<01:12,  4.61trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 34%|███████▏             | 170/500 [00:42<00:59,  5.56trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 34%|███████▏             | 172/500 [00:42<00:58,  5.59trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 35%|███████▎             | 173/500 [00:42<00:55,  5.90trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 35%|███████▎             | 174/500 [00:43<00:51,  6.28trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 35%|███████▎             | 175/500 [00:43<01:35,  3.40trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 35%|███████▍             | 176/500 [00:44<01:43,  3.12trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 35%|███████▍             | 177/500 [00:44<01:35,  3.39trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 36%|███████▍             | 178/500 [00:45<02:30,  2.15trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 36%|███████▌             | 180/500 [00:45<02:00,  2.65trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 36%|███████▋             | 182/500 [00:46<01:25,  3.74trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 37%|███████▋             | 184/500 [00:46<01:09,  4.53trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 37%|███████▊             | 186/500 [00:46<01:01,  5.08trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 37%|███████▊             | 187/500 [00:47<01:01,  5.05trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 38%|███████▉             | 189/500 [00:47<01:14,  4.18trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 38%|████████             | 191/500 [00:48<01:06,  4.64trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 38%|████████             | 191/500 [00:48<01:06,  4.64trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 39%|████████             | 193/500 [00:48<01:08,  4.47trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 39%|████████▏            | 195/500 [00:48<00:57,  5.26trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 39%|████████▎            | 197/500 [00:49<01:29,  3.40trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 40%|████████▎            | 199/500 [00:50<01:14,  4.01trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 40%|████████▍            | 201/500 [00:50<01:07,  4.41trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 41%|████████▌            | 203/500 [00:51<01:12,  4.09trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 41%|████████▌            | 203/500 [00:51<01:12,  4.09trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 41%|████████▌            | 204/500 [00:51<01:40,  2.96trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 41%|████████▌            | 205/500 [00:52<01:47,  2.74trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 41%|████████▋            | 206/500 [00:52<02:01,  2.42trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 42%|████████▋            | 208/500 [00:53<01:34,  3.08trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 42%|████████▊            | 209/500 [00:53<01:27,  3.34trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 42%|████████▊            | 210/500 [00:53<01:26,  3.37trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 42%|████████▊            | 211/500 [00:53<01:20,  3.57trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 42%|████████▉            | 212/500 [00:54<01:30,  3.19trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 43%|████████▉            | 213/500 [00:54<01:39,  2.89trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 43%|████████▉            | 214/500 [00:55<01:37,  2.93trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 43%|█████████            | 216/500 [00:55<01:24,  3.36trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 44%|█████████▏           | 218/500 [00:55<01:02,  4.50trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 44%|█████████▏           | 220/500 [00:56<00:52,  5.34trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 44%|█████████▎           | 222/500 [00:56<00:47,  5.88trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 45%|█████████▎           | 223/500 [00:56<00:53,  5.20trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 45%|█████████▍           | 225/500 [00:57<00:54,  5.02trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 45%|█████████▌           | 227/500 [00:57<00:51,  5.25trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 45%|█████████▌           | 227/500 [00:58<00:51,  5.25trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 46%|█████████▌           | 228/500 [00:58<01:41,  2.67trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 46%|█████████▌           | 229/500 [00:58<01:45,  2.58trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 46%|█████████▋           | 230/500 [00:59<01:38,  2.75trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 46%|█████████▋           | 232/500 [00:59<01:25,  3.14trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 46%|█████████▋           | 232/500 [00:59<01:25,  3.14trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 47%|█████████▊           | 234/500 [01:00<01:11,  3.71trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 47%|█████████▉           | 236/500 [01:00<00:53,  4.93trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 48%|█████████▉           | 238/500 [01:00<00:44,  5.87trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 48%|██████████           | 240/500 [01:01<00:46,  5.60trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 48%|██████████           | 241/500 [01:01<00:42,  6.08trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 49%|██████████▏          | 243/500 [01:01<00:38,  6.65trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 49%|██████████▎          | 245/500 [01:01<00:36,  6.98trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 49%|██████████▎          | 247/500 [01:02<00:37,  6.79trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|██████████▍          | 249/500 [01:02<00:37,  6.74trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|██████████▌          | 250/500 [01:02<01:02,  4.01trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      " 50%|██████████▌          | 252/500 [01:03<01:18,  3.14trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 51%|██████████▋          | 253/500 [01:03<01:11,  3.46trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 51%|██████████▋          | 255/500 [01:04<01:12,  3.38trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 51%|██████████▊          | 256/500 [01:04<01:03,  3.86trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 51%|██████████▊          | 257/500 [01:04<01:01,  3.93trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 52%|██████████▊          | 258/500 [01:05<01:07,  3.59trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 52%|██████████▉          | 259/500 [01:05<01:11,  3.39trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 52%|██████████▉          | 260/500 [01:05<01:10,  3.39trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 52%|██████████▉          | 261/500 [01:06<01:11,  3.35trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 53%|███████████          | 263/500 [01:06<01:05,  3.64trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      " 53%|███████████▏         | 265/500 [01:07<00:52,  4.43trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 53%|███████████▏         | 267/500 [01:07<00:43,  5.30trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 54%|███████████▎         | 269/500 [01:07<00:40,  5.77trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 54%|███████████▍         | 271/500 [01:08<00:49,  4.63trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 55%|███████████▍         | 273/500 [01:08<00:42,  5.30trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 55%|███████████▌         | 275/500 [01:08<00:37,  6.01trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 55%|███████████▋         | 277/500 [01:09<00:36,  6.04trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 56%|███████████▋         | 279/500 [01:09<00:35,  6.22trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 56%|███████████▊         | 281/500 [01:09<00:34,  6.27trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 57%|███████████▉         | 283/500 [01:10<00:37,  5.80trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 57%|███████████▉         | 284/500 [01:10<01:10,  3.06trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 57%|████████████         | 286/500 [01:11<00:54,  3.93trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 58%|████████████         | 288/500 [01:11<00:45,  4.66trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 58%|████████████▏        | 290/500 [01:11<00:38,  5.46trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 58%|████████████▏        | 291/500 [01:12<00:36,  5.71trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 58%|████████████▎        | 292/500 [01:12<00:56,  3.69trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 59%|████████████▎        | 294/500 [01:13<01:22,  2.49trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 59%|████████████▍        | 296/500 [01:14<01:02,  3.25trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 59%|████████████▍        | 297/500 [01:14<00:53,  3.80trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 60%|████████████▌        | 298/500 [01:15<01:17,  2.59trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 60%|████████████▌        | 299/500 [01:15<01:25,  2.36trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:53] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 60%|████████████▌        | 300/500 [01:16<02:05,  1.59trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 60%|████████████▋        | 301/500 [01:17<01:42,  1.94trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 60%|████████████▋        | 302/500 [01:17<01:28,  2.23trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 61%|████████████▊        | 304/500 [01:17<01:11,  2.74trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 61%|████████████▊        | 306/500 [01:18<00:50,  3.88trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 62%|████████████▉        | 308/500 [01:18<00:39,  4.89trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 62%|████████████▉        | 309/500 [01:18<00:41,  4.65trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 62%|█████████████        | 311/500 [01:19<00:43,  4.34trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 62%|█████████████        | 312/500 [01:19<00:39,  4.78trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 63%|█████████████▏       | 314/500 [01:20<00:43,  4.26trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 63%|█████████████▎       | 316/500 [01:20<00:36,  5.02trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 64%|█████████████▎       | 318/500 [01:20<00:30,  6.01trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 64%|█████████████▍       | 320/500 [01:20<00:29,  6.01trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 64%|█████████████▍       | 321/500 [01:21<00:29,  6.06trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 65%|█████████████▌       | 323/500 [01:21<00:31,  5.68trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 65%|█████████████▋       | 325/500 [01:21<00:32,  5.36trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:19:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 65%|█████████████▋       | 327/500 [01:22<00:29,  5.84trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 66%|█████████████▊       | 329/500 [01:22<00:29,  5.71trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 66%|█████████████▊       | 330/500 [01:22<00:31,  5.46trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:19:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 66%|█████████████▉       | 332/500 [01:24<01:02,  2.67trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 67%|█████████████▉       | 333/500 [01:24<00:51,  3.23trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 67%|██████████████       | 335/500 [01:24<00:40,  4.08trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 67%|██████████████       | 336/500 [01:24<00:38,  4.25trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 68%|██████████████▏      | 338/500 [01:25<00:37,  4.32trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 68%|██████████████▎      | 340/500 [01:25<00:35,  4.49trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 68%|██████████████▎      | 340/500 [01:25<00:35,  4.49trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 68%|██████████████▎      | 341/500 [01:26<00:39,  4.05trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 68%|██████████████▎      | 342/500 [01:26<00:45,  3.48trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 69%|██████████████▍      | 343/500 [01:26<00:43,  3.58trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 69%|██████████████▍      | 345/500 [01:27<00:36,  4.20trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 69%|██████████████▌      | 347/500 [01:27<00:30,  5.08trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 70%|██████████████▋      | 349/500 [01:27<00:30,  4.88trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 70%|██████████████▋      | 350/500 [01:27<00:27,  5.44trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 70%|██████████████▋      | 351/500 [01:28<00:29,  5.09trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 70%|██████████████▊      | 352/500 [01:28<00:36,  4.08trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 71%|██████████████▊      | 353/500 [01:28<00:37,  3.92trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 71%|██████████████▊      | 354/500 [01:29<00:40,  3.59trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 71%|██████████████▉      | 355/500 [01:29<00:47,  3.05trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 71%|██████████████▉      | 356/500 [01:30<00:56,  2.53trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 71%|██████████████▉      | 357/500 [01:30<00:55,  2.58trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 72%|███████████████      | 358/500 [01:31<01:16,  1.87trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 72%|███████████████      | 359/500 [01:31<01:08,  2.07trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 72%|███████████████      | 360/500 [01:32<01:02,  2.23trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 72%|███████████████▏     | 361/500 [01:32<01:01,  2.25trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 72%|███████████████▏     | 362/500 [01:32<00:53,  2.57trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:10] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 73%|███████████████▏     | 363/500 [01:33<01:12,  1.89trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 73%|███████████████▎     | 365/500 [01:34<00:52,  2.55trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 73%|███████████████▎     | 366/500 [01:34<00:42,  3.13trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      " 74%|███████████████▍     | 368/500 [01:35<00:50,  2.61trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 74%|███████████████▌     | 370/500 [01:35<00:42,  3.09trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 74%|███████████████▌     | 371/500 [01:36<00:37,  3.41trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 75%|███████████████▋     | 373/500 [01:36<00:36,  3.45trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 75%|███████████████▋     | 374/500 [01:36<00:33,  3.79trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 75%|███████████████▊     | 375/500 [01:37<00:29,  4.19trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 75%|███████████████▊     | 377/500 [01:37<00:25,  4.81trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 76%|███████████████▉     | 379/500 [01:37<00:23,  5.16trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 76%|███████████████▉     | 380/500 [01:38<00:22,  5.26trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 76%|████████████████     | 382/500 [01:38<00:22,  5.15trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 77%|████████████████▏    | 384/500 [01:38<00:19,  5.95trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 77%|████████████████▏    | 385/500 [01:38<00:19,  6.03trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 77%|████████████████▎    | 387/500 [01:39<00:23,  4.73trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 77%|████████████████▎    | 387/500 [01:39<00:23,  4.73trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 78%|████████████████▎    | 389/500 [01:40<00:36,  3.04trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 78%|████████████████▍    | 391/500 [01:41<00:35,  3.08trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 78%|████████████████▍    | 392/500 [01:41<00:29,  3.65trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 79%|████████████████▌    | 394/500 [01:41<00:28,  3.66trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 79%|████████████████▋    | 396/500 [01:42<00:23,  4.46trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 80%|████████████████▋    | 398/500 [01:42<00:21,  4.85trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 80%|████████████████▊    | 400/500 [01:42<00:19,  5.13trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 80%|████████████████▉    | 402/500 [01:43<00:19,  5.08trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 81%|████████████████▉    | 403/500 [01:43<00:18,  5.21trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 81%|█████████████████    | 405/500 [01:43<00:16,  5.65trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 81%|█████████████████    | 406/500 [01:44<00:19,  4.79trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 81%|█████████████████    | 407/500 [01:44<00:21,  4.37trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 82%|█████████████████▏   | 408/500 [01:44<00:22,  4.11trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 82%|█████████████████▏   | 410/500 [01:45<00:19,  4.59trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 82%|█████████████████▎   | 412/500 [01:45<00:16,  5.44trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 83%|█████████████████▍   | 414/500 [01:45<00:14,  6.07trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 83%|█████████████████▍   | 416/500 [01:46<00:15,  5.57trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 83%|█████████████████▌   | 417/500 [01:46<00:13,  5.94trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 84%|█████████████████▌   | 419/500 [01:46<00:12,  6.28trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 84%|█████████████████▋   | 421/500 [01:46<00:12,  6.48trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 84%|█████████████████▋   | 422/500 [01:46<00:11,  6.63trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 85%|█████████████████▊   | 423/500 [01:47<00:20,  3.68trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 85%|█████████████████▊   | 425/500 [01:48<00:21,  3.41trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 85%|█████████████████▉   | 426/500 [01:48<00:19,  3.73trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 86%|█████████████████▉   | 428/500 [01:48<00:18,  3.91trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 86%|██████████████████   | 429/500 [01:49<00:17,  4.06trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 86%|██████████████████   | 431/500 [01:50<00:22,  3.05trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 86%|██████████████████▏  | 432/500 [01:50<00:19,  3.54trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 87%|██████████████████▏  | 434/500 [01:50<00:16,  3.96trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 87%|██████████████████▎  | 435/500 [01:51<00:17,  3.67trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 87%|██████████████████▎  | 436/500 [01:51<00:16,  3.78trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 88%|██████████████████▍  | 438/500 [01:51<00:14,  4.25trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 88%|██████████████████▍  | 440/500 [01:52<00:12,  5.00trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 88%|██████████████████▌  | 442/500 [01:52<00:10,  5.34trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 89%|██████████████████▋  | 444/500 [01:52<00:10,  5.49trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 89%|██████████████████▋  | 446/500 [01:53<00:09,  5.89trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 90%|██████████████████▊  | 448/500 [01:53<00:09,  5.60trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 90%|██████████████████▊  | 449/500 [01:53<00:10,  4.80trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 90%|██████████████████▉  | 450/500 [01:54<00:12,  3.86trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 90%|██████████████████▉  | 451/500 [01:54<00:19,  2.47trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 91%|███████████████████  | 453/500 [01:55<00:17,  2.67trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 91%|███████████████████  | 455/500 [01:56<00:18,  2.37trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 91%|███████████████████  | 455/500 [01:56<00:18,  2.37trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 91%|███████████████████▏ | 457/500 [01:57<00:14,  3.04trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 92%|███████████████████▏ | 458/500 [01:57<00:11,  3.51trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 92%|███████████████████▎ | 460/500 [01:57<00:09,  4.07trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 92%|███████████████████▍ | 462/500 [01:58<00:07,  5.11trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 93%|███████████████████▍ | 464/500 [01:58<00:06,  5.89trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 93%|███████████████████▌ | 466/500 [01:58<00:05,  6.25trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 94%|███████████████████▋ | 468/500 [01:58<00:04,  6.41trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 94%|███████████████████▋ | 470/500 [01:59<00:04,  6.60trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 94%|███████████████████▊ | 472/500 [01:59<00:04,  6.59trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 95%|███████████████████▉ | 474/500 [01:59<00:04,  6.50trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 95%|███████████████████▉ | 476/500 [02:00<00:03,  6.08trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 96%|████████████████████ | 478/500 [02:00<00:04,  5.47trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 96%|████████████████████ | 478/500 [02:00<00:04,  5.47trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 96%|████████████████████ | 479/500 [02:01<00:08,  2.51trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 96%|████████████████████▏| 481/500 [02:01<00:07,  2.67trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 96%|████████████████████▏| 482/500 [02:02<00:04,  3.72trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 97%|████████████████████▎| 484/500 [02:02<00:03,  4.18trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 97%|████████████████████▎| 485/500 [02:03<00:04,  3.29trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 97%|████████████████████▍| 487/500 [02:03<00:03,  3.49trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 98%|████████████████████▌| 489/500 [02:03<00:02,  4.43trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 98%|████████████████████▌| 491/500 [02:04<00:01,  5.27trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 99%|████████████████████▋| 493/500 [02:05<00:01,  3.79trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 99%|████████████████████▊| 495/500 [02:05<00:01,  4.60trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 99%|████████████████████▊| 497/500 [02:05<00:00,  5.13trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:20:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:20:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████████████████▉| 499/500 [02:06<00:00,  5.70trial/s, best loss: -0.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 500/500 [02:06<00:00,  3.96trial/s, best loss: -0.9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "\n",
    "def gbm_objective(search_space):\n",
    "    model = XGBClassifier(**search_space)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "\n",
    "# new search space\n",
    "search_space={'loss':hp.choice('loss', ['deviance', 'exponential']),\n",
    "              'max_depth':hp.choice('max_depth', range(2, 10)),\n",
    "              'min_samples_split':hp.uniform('min_samples_split', 0.1, 1),\n",
    "              'min_samples_leaf':hp.choice('min_samples_leaf', range(1, 30)),\n",
    "              'max_features':hp.choice('max_features', [None, 'sqrt', 'log2']),\n",
    "              'min_impurity_decrease':hp.uniform('min_impurity_decrease', 0.1, 1),\n",
    "              'ccp_alpha':hp.uniform('ccp_alpha', 0.01, 1),\n",
    "              'learning_rate':hp.choice('learning_rate', [0.1, 0.01]),\n",
    "              'n_estimators':hp.choice('n_estimators', [100, 200, 300, 400, 500,1000])}\n",
    "\n",
    "# set the hyperparam tuning algorithm\n",
    "algorithm=tpe.suggest\n",
    "# implement Hyperopt\n",
    "best_params = fmin(fn=gbm_objective,\n",
    "                   space=search_space,\n",
    "                   algo=algorithm,\n",
    "                   max_evals=500)\n",
    "\n",
    "xgb_params = space_eval(search_space, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5eeca5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "[09:33:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-----\n",
      "오차 행렬\n",
      " [[57  2]\n",
      " [ 7 24]]\n",
      "정확도(accuracy) : 0.90\n",
      "정밀도(precision) : 0.92\n",
      "재현율(recall) : 0.77\n",
      "f1 Score : 0.84\n",
      "AUC : 0.87\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9,\n",
       " 0.9230769230769231,\n",
       " 0.7741935483870968,\n",
       " 0.8421052631578947,\n",
       " 0.8701476216511754)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"XGBClassifier\")\n",
    "xgb = XGBClassifier(**xgb_params)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_dt_pred = xgb.predict(X_test)\n",
    "get_clf_eval(y_test, xgb_dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c318cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(**xgb_params)\n",
    "xgb.fit(X, y)\n",
    "xgb_clf_pred = xgb.predict(df_test)\n",
    "df_test['survived'] = xgb_clf_pred\n",
    "\n",
    "# 파일 저장\n",
    "tit = pd.read_csv('./test.csv')\n",
    "tit.drop(list(tit.columns)[1:], axis = 1, inplace=True)\n",
    "tit['Survived'] = df_test['survived']\n",
    "tit.set_index('PassengerId', inplace=True)\n",
    "tit.to_csv('tit_test_xgv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56c11ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "오차 행렬\n",
      " [[55  4]\n",
      " [ 7 24]]\n",
      "정확도(accuracy) : 0.88\n",
      "정밀도(precision) : 0.86\n",
      "재현율(recall) : 0.77\n",
      "f1 Score : 0.81\n",
      "AUC : 0.85\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8777777777777778,\n",
       " 0.8571428571428571,\n",
       " 0.7741935483870968,\n",
       " 0.8135593220338982,\n",
       " 0.8531984691088026)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgb_clf = HistGradientBoostingClassifier()\n",
    "hgb_clf.fit(X_train, y_train)\n",
    "hgb_clf_pred = hgb_clf.predict(X_test)\n",
    "get_clf_eval(y_test, hgb_clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3578307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb_clf = HistGradientBoostingClassifier()\n",
    "hgb_clf.fit(X, y)\n",
    "hgb_clf_pred = hgb_clf.predict(df_test)\n",
    "df_test['survived'] = hgb_clf_pred\n",
    "\n",
    "# 파일 저장\n",
    "tit = pd.read_csv('./test.csv')\n",
    "tit.drop(list(tit.columns)[1:], axis = 1, inplace=True)\n",
    "tit['Survived'] = df_test['survived']\n",
    "tit.set_index('PassengerId', inplace=True)\n",
    "tit.to_csv('tit_test_hgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "04a2b4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████| 500/500 [10:34<00:00,  1.27s/trial, best loss: -0.9111111111111111]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "\n",
    "def gbm_objective(search_space):\n",
    "    model = HistGradientBoostingClassifier(**search_space)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "\n",
    "# new search space\n",
    "search_space={'loss':hp.choice('loss', [\"auto\"]),\n",
    "              'learning_rate':hp.choice('learning_rate', [0.1, 1]),\n",
    "              'max_iter':hp.choice('max_iter', range(1, 1000)),\n",
    "              'max_leaf_nodes':hp.choice('max_leaf_nodes', range(2, 31)),\n",
    "              'max_depth':hp.choice('max_depth', range(1, 100)),\n",
    "              'min_samples_leaf':hp.choice('min_samples_leaf', range(1, 30)),\n",
    "#               'l2_regularization':hp.uniform('l2_regularization', [0, 1]),\n",
    "              'max_bins':hp.choice('max_bins', range(2, 255)),\n",
    "              'validation_fraction':hp.choice('validation_fraction', [i *0.01 for i in range(1, 10)]),\n",
    "              'random_state':hp.choice('random_state', range(1, 300))}\n",
    "\n",
    "# set the hyperparam tuning algorithm\n",
    "algorithm=tpe.suggest\n",
    "# implement Hyperopt\n",
    "best_params = fmin(fn=gbm_objective,\n",
    "                   space=search_space,\n",
    "                   algo=algorithm,\n",
    "                   max_evals=500)\n",
    "\n",
    "params1 = space_eval(search_space, best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e9fb4c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "오차 행렬\n",
      " [[57  2]\n",
      " [ 6 25]]\n",
      "정확도(accuracy) : 0.91\n",
      "정밀도(precision) : 0.93\n",
      "재현율(recall) : 0.81\n",
      "f1 Score : 0.86\n",
      "AUC : 0.89\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9111111111111111,\n",
       " 0.9259259259259259,\n",
       " 0.8064516129032258,\n",
       " 0.8620689655172414,\n",
       " 0.8862766539092399)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgb_clf = HistGradientBoostingClassifier(**params1)\n",
    "hgb_clf.fit(X_train, y_train)\n",
    "hgb_clf_pred = hgb_clf.predict(X_test)\n",
    "get_clf_eval(y_test, hgb_clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4f390fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb_clf = HistGradientBoostingClassifier(**params1)\n",
    "hgb_clf.fit(X, y)\n",
    "hgb_clf_pred = hgb_clf.predict(df_test)\n",
    "df_test['survived'] = hgb_clf_pred\n",
    "\n",
    "# 파일 저장\n",
    "tit = pd.read_csv('./test.csv')\n",
    "tit.drop(list(tit.columns)[1:], axis = 1, inplace=True)\n",
    "tit['Survived'] = df_test['survived']\n",
    "tit.set_index('PassengerId', inplace=True)\n",
    "tit.to_csv('tit_test_hgb_hp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "61f3e23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "오차 행렬\n",
      " [[57  2]\n",
      " [10 21]]\n",
      "정확도(accuracy) : 0.87\n",
      "정밀도(precision) : 0.91\n",
      "재현율(recall) : 0.68\n",
      "f1 Score : 0.78\n",
      "AUC : 0.82\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8666666666666667,\n",
       " 0.9130434782608695,\n",
       " 0.6774193548387096,\n",
       " 0.7777777777777777,\n",
       " 0.8217605248769819)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:49:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:58:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:58:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:58:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:58:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:00:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:00:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:56:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:56:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:59:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:59:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:58:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:58:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "hgb_clf = HistGradientBoostingClassifier(**params1)\n",
    "xgb_clf = XGBClassifier(**xgb_params)\n",
    "best_gbm_clf = GradientBoostingClassifier(**gb_params)\n",
    "etsc_clf = ExtraTreesClassifier()\n",
    "etsc_best_clf = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, bootstrap=True, random_state=10, max_samples=1.0)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, criterion='entropy', max_features=None,)\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, max_samples=1.0, bootstrap=False, n_jobs=-1,\n",
    "                            bootstrap_features=True, max_features=0.5, oob_score=False, )\n",
    "\n",
    "\n",
    "voting_model = VotingClassifier(estimators=[('HistGradientBoostingClassifier', hgb_clf), ('XGBClassifier', xgb_clf),\n",
    "                                            ('GradientBoostingClassifier', best_gbm_clf)], voting='soft', n_jobs=-1)\n",
    "voting_model_2 = VotingClassifier(estimators=[('RandomForestClassifier', rnd_clf), ('ExtraTreesClassifier', etsc_best_clf),\n",
    "                                            ('BaggingClassifier', bag_clf)], voting='soft', n_jobs=-1)\n",
    "voting_model.fit(X_train, y_train)\n",
    "voting_model_dt_pred = voting_model.predict(X_test)\n",
    "voting_model_2.fit(X_train, y_train)\n",
    "voting_model_2_dt_pred = voting_model_2.predict(X_test)\n",
    "\n",
    "\n",
    "get_clf_eval(y_test, voting_model_dt_pred)\n",
    "\n",
    "# -----\n",
    "# 오차 행렬\n",
    "#  [[57  2]\n",
    "#  [12 19]]\n",
    "# 정확도(accuracy) : 0.84\n",
    "# 정밀도(precision) : 0.90\n",
    "# 재현율(recall) : 0.61\n",
    "# f1 Score : 0.73\n",
    "# AUC : 0.79\n",
    "# -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d281534b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "voting_model.fit(X, y)\n",
    "voting_model_dt_pred = voting_model.predict(df_test)\n",
    "df_test['survived'] = voting_model_dt_pred\n",
    "\n",
    "# 파일 저장\n",
    "tit = pd.read_csv('./test.csv')\n",
    "tit.drop(list(tit.columns)[1:], axis = 1, inplace=True)\n",
    "tit['Survived'] = df_test['survived']\n",
    "tit.set_index('PassengerId', inplace=True)\n",
    "tit.to_csv('tit_test_voting6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5a73afb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "{'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2'}\n",
      "[11:28:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=sqrt; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=log2; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=log2; total time=   0.2s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=sqrt; total time=   0.2s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=sqrt; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=log2; total time=   0.3s\n",
      "[11:26:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=sqrt; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=log2; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=sqrt; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....criterion=gini, max_depth=6, max_features=sqrt; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=log2; total time=   0.2s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=log2; total time=   0.3s\n",
      "[11:26:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=log2; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=log2; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=log2; total time=   0.2s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=sqrt; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....criterion=gini, max_depth=3, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=sqrt; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=log2; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=log2; total time=   0.2s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=log2; total time=   0.4s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=log2; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=sqrt; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=log2; total time=   0.2s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=log2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....criterion=gini, max_depth=6, max_features=log2; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=sqrt; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=None; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=sqrt; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=log2; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=sqrt; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=sqrt; total time=   0.2s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=log2; total time=   0.2s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=log2; total time=   0.2s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=sqrt; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=None; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....criterion=gini, max_depth=5, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=log2; total time=   0.2s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=sqrt; total time=   0.2s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=sqrt; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=3, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=4, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=sqrt; total time=   0.2s\n",
      "[CV] END .....criterion=gini, max_depth=5, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=6, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=7, max_features=None; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=8, max_features=log2; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=9, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=sqrt; total time=   0.2s\n",
      "[CV] END ....criterion=gini, max_depth=10, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=11, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=12, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=13, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=14, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=15, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=16, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=17, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=18, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=19, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=20, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=21, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=22, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=23, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=24, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=25, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=26, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=27, max_features=log2; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=28, max_features=None; total time=   0.3s\n",
      "[CV] END ....criterion=gini, max_depth=29, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=3, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=4, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=5, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=sqrt; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=6, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=7, max_features=None; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=8, max_features=log2; total time=   0.3s\n",
      "[CV] END ..criterion=entropy, max_depth=9, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=10, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=11, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=12, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=13, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=14, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=15, max_features=None; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=16, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=17, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=18, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=19, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=20, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=21, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=22, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=23, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=24, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=25, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=26, max_features=log2; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=27, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=sqrt; total time=   0.3s\n",
      "[CV] END .criterion=entropy, max_depth=28, max_features=None; total time=   0.4s\n",
      "[CV] END .criterion=entropy, max_depth=29, max_features=None; total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "params = {'criterion':['gini', 'entropy'],\n",
    "          'max_depth':range(3, 30),\n",
    "#           'min_samples_split':range(2, 30),\n",
    "#           'min_samples_leaf':range(1, 20),\n",
    "          'max_features':[\"sqrt\", \"log2\", None]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rnd_clf = RandomForestClassifier()\n",
    "gs_rndclf = GridSearchCV(rnd_clf, param_grid=params, scoring='accuracy', n_jobs=-1, cv=5, verbose=2)\n",
    "gs_rndclf.fit(X_train, y_train)\n",
    "print(gs_rndclf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5984c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, criterion='entropy', max_features=None,)\n",
    "et_clf = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, bootstrap=True, random_state=10, max_samples=1.0)\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, max_samples=1.0, bootstrap=False, n_jobs=-1,\n",
    "                            bootstrap_features=True, max_features=0.5, oob_score=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5419cecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "오차 행렬\n",
      " [[58  1]\n",
      " [11 20]]\n",
      "정확도(accuracy) : 0.87\n",
      "정밀도(precision) : 0.95\n",
      "재현율(recall) : 0.65\n",
      "f1 Score : 0.77\n",
      "AUC : 0.81\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8666666666666667,\n",
       " 0.9523809523809523,\n",
       " 0.6451612903225806,\n",
       " 0.7692307692307692,\n",
       " 0.814106068890104)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, criterion='entropy', max_features=None,)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "rnd_clf_pred = rnd_clf.predict(X_test)\n",
    "get_clf_eval(y_test, rnd_clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c6e4195a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "오차 행렬\n",
      " [[57  2]\n",
      " [11 20]]\n",
      "정확도(accuracy) : 0.86\n",
      "정밀도(precision) : 0.91\n",
      "재현율(recall) : 0.65\n",
      "f1 Score : 0.75\n",
      "AUC : 0.81\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8555555555555555,\n",
       " 0.9090909090909091,\n",
       " 0.6451612903225806,\n",
       " 0.7547169811320754,\n",
       " 0.8056314926189173)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_clf = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, bootstrap=True, random_state=10, max_samples=1.0)\n",
    "et_clf.fit(X_train, y_train)\n",
    "et_clf_pred = et_clf.predict(X_test)\n",
    "get_clf_eval(y_test, et_clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c835093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "오차 행렬\n",
      " [[56  3]\n",
      " [10 21]]\n",
      "정확도(accuracy) : 0.86\n",
      "정밀도(precision) : 0.88\n",
      "재현율(recall) : 0.68\n",
      "f1 Score : 0.76\n",
      "AUC : 0.81\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8555555555555555,\n",
       " 0.875,\n",
       " 0.6774193548387096,\n",
       " 0.7636363636363636,\n",
       " 0.8132859486057955)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, max_samples=1.0, bootstrap=False, n_jobs=-1,\n",
    "                            bootstrap_features=True, max_features=0.5, oob_score=False, )\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf_pred = bag_clf.predict(X_test)\n",
    "get_clf_eval(y_test, bag_clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ea1b2e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in ./opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (2.2.0)\n",
      "Collecting scikit-learn>=1.1.0\n",
      "  Downloading scikit_learn-1.1.2-cp39-cp39-macosx_10_9_x86_64.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.1.0)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "Successfully installed imbalanced-learn-0.9.1 scikit-learn-1.1.2\n"
     ]
    }
   ],
   "source": [
    "# 1021\n",
    "# SMOTE PACKAGE\n",
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "953816a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e28956ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy=\"auto\",\n",
    "          random_state=19,\n",
    "          k_neighbors=5,\n",
    "          n_jobs=4)\n",
    "\n",
    "X_rsmp, y_rsmp = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc960206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "오차 행렬\n",
      " [[55  4]\n",
      " [10 21]]\n",
      "정확도(accuracy) : 0.84\n",
      "정밀도(precision) : 0.84\n",
      "재현율(recall) : 0.68\n",
      "f1 Score : 0.75\n",
      "AUC : 0.80\n",
      "-----\n",
      "-----\n",
      "오차 행렬\n",
      " [[54  5]\n",
      " [ 5 26]]\n",
      "정확도(accuracy) : 0.89\n",
      "정밀도(precision) : 0.84\n",
      "재현율(recall) : 0.84\n",
      "f1 Score : 0.84\n",
      "AUC : 0.88\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8888888888888888,\n",
       " 0.8387096774193549,\n",
       " 0.8387096774193549,\n",
       " 0.8387096774193549,\n",
       " 0.8769819573537453)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf1 = BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, max_samples=1.0, bootstrap=False, n_jobs=-1,\n",
    "                            bootstrap_features=True, max_features=0.5, oob_score=False, )\n",
    "bag_clf1.fit(X_train, y_train)\n",
    "bag_clf_pred1 = bag_clf1.predict(X_test)\n",
    "get_clf_eval(y_test, bag_clf_pred1)\n",
    "\n",
    "bag_clf2 = BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, max_samples=1.0, bootstrap=False, n_jobs=-1,\n",
    "                            bootstrap_features=True, max_features=0.5, oob_score=False, )\n",
    "bag_clf2.fit(X_rsmp, y_rsmp)\n",
    "bag_clf_pred2 = bag_clf2.predict(X_test)\n",
    "get_clf_eval(y_test, bag_clf_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7509a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89        59\n",
      "           1       0.84      0.68      0.75        31\n",
      "\n",
      "    accuracy                           0.84        90\n",
      "   macro avg       0.84      0.80      0.82        90\n",
      "weighted avg       0.84      0.84      0.84        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       490\n",
      "           1       0.87      0.82      0.85       490\n",
      "\n",
      "    accuracy                           0.85       980\n",
      "   macro avg       0.85      0.85      0.85       980\n",
      "weighted avg       0.85      0.85      0.85       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, bag_clf1.predict(X_test)))\n",
    "print(metrics.classification_report(y_rsmp, bag_clf2.predict(X_rsmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "004dc78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54,  5],\n",
       "       [ 5, 26]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, bag_clf_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66da3e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  54   5\n",
       "1   5  26"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, bag_clf_pred2), columns=['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0aa93de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array([bag_clf_pred, et_clf_pred, rnd_clf_pred, hgb_clf_pred, xgb_dt_pred, voting_model_2_dt_pred, gbc_dt_pred, best_gbm_clf_pred, hgb_clf_best_pred, bag_clf2_pred,dt_clf_best_pred]).T\n",
    "dc_final = DecisionTreeClassifier()\n",
    "dc_final.fit(pred, y_test)\n",
    "final = dc_final.predict(pred)\n",
    "accuracy_score(y_test, final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "44bab909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Embarked\n",
      "- Name\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 8 features, but BaggingClassifier is expecting 6 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [133]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# STACKING\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m bag_clf_pred1 \u001b[38;5;241m=\u001b[39m \u001b[43mbag_clf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([bag_clf_pred, et_clf_pred, rnd_clf_pred, hgb_clf_pred, xgb_dt_pred, voting_model_2_dt_pred, gbc_dt_pred, best_gbm_clf_pred, hgb_clf_best_pred, bag_clf2_pred,dt_clf_best_pred , y_test])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124met\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrnd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhgb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m4\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m5\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoting\u001b[39m\u001b[38;5;124m\"\u001b[39m ,\u001b[38;5;241m6\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgbc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m7\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_bgm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m8\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_hgb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m9\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbag_clf2_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m10\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt_clf_best\u001b[39m\u001b[38;5;124m'\u001b[39m ,\u001b[38;5;241m11\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:785\u001b[0m, in \u001b[0;36mBaggingClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;124;03m\"\"\"Predict class for X.\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03m    The predicted class of an input sample is computed as the class with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 785\u001b[0m     predicted_probabilitiy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake((np\u001b[38;5;241m.\u001b[39margmax(predicted_probabilitiy, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:812\u001b[0m, in \u001b[0;36mBaggingClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    810\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 812\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;66;03m# Parallel loop\u001b[39;00m\n\u001b[1;32m    821\u001b[0m n_jobs, n_estimators, starts \u001b[38;5;241m=\u001b[39m _partition_estimators(\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    823\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 8 features, but BaggingClassifier is expecting 6 features as input."
     ]
    }
   ],
   "source": [
    "# STACKING\n",
    "\n",
    "bag_clf_pred1 = bag_clf1.predict(df_test)\n",
    "df = pd.DataFrame([bag_clf_pred, et_clf_pred, rnd_clf_pred, hgb_clf_pred, xgb_dt_pred, voting_model_2_dt_pred, gbc_dt_pred, best_gbm_clf_pred, hgb_clf_best_pred, bag_clf2_pred,dt_clf_best_pred , y_test]).T\n",
    "df = df.rename(columns={0:\"bag\", 1:\"et\", 2:\"rnd\", 3:\"hgb\",4:\"xgb\",5:\"voting\" ,6:\"gbc\",7:\"best_bgm\", 8:\"best_hgb\",9:\"bag_clf2_pred\",10:'dt_clf_best' ,11:\"result\"})\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df\n",
    "\n",
    "pred = np.array([bag_clf_pred, et_clf_pred, rnd_clf_pred, hgb_clf_pred, xgb_dt_pred, voting_model_2_dt_pred, gbc_dt_pred, best_gbm_clf_pred, hgb_clf_best_pred, bag_clf2_pred,dt_clf_best_pred]).T\n",
    "dc_final = DecisionTreeClassifier()\n",
    "dc_final.fit(pred, y_test)\n",
    "final = dc_final.predict(pred)\n",
    "accuracy_score(y_test, final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8a02242f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.5803345757292036,\n",
       " 'learning_rate': 0.01,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_impurity_decrease': 0.21694403720395206,\n",
       " 'min_samples_leaf': 13,\n",
       " 'min_samples_split': 0.524057300043958,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5ba7a501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "오차 행렬\n",
      " [[57  2]\n",
      " [11 20]]\n",
      "정확도(accuracy) : 0.86\n",
      "정밀도(precision) : 0.91\n",
      "재현율(recall) : 0.65\n",
      "f1 Score : 0.75\n",
      "AUC : 0.81\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:35:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:1823: FutureWarning: The loss 'auto' was deprecated in v1.1 and will be removed in version 1.3. Use 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:35:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "dtclf = DecisionTreeClassifier(max_depth=5) #ccp : 분기점\n",
    "dtclf.fit(X_train, y_train)\n",
    "dt_pred = dtclf.predict(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=10000, n_jobs=-1) \n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_dt_pred = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, \n",
    "                                 criterion='entropy', max_features=None,)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "rnd_clf_dt_pred = rnd_clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etsc = ExtraTreesClassifier()\n",
    "etsc.fit(X_train, y_train)\n",
    "etsc_dt_pred = etsc.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "et_clf = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, \n",
    "                              bootstrap=True, random_state=10, max_samples=1.0)\n",
    "et_clf.fit(X_train, y_train)\n",
    "et_clf_dt_pred = et_clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtclf = DecisionTreeClassifier(max_depth=5) \n",
    "dtclf.fit(X_train, y_train)\n",
    "dtclf_dt_pred = dtclf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, \n",
    "                            max_samples=1.0, bootstrap=False, n_jobs=-1,\n",
    "                            bootstrap_features=True, max_features=0.5, oob_score=False)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf_dt_pred = bag_clf.predict(X_test)\n",
    "get_clf_eval(y_test, bag_clf_dt_pred)\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtclf = DecisionTreeClassifier() \n",
    "dtclf.fit(X_train, y_train)\n",
    "dtclf_dt_pred = dtclf.predict(X_test)\n",
    "\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "etc = ExtraTreeClassifier() \n",
    "etc.fit(X_train, y_train)\n",
    "etc_dt_pred = etc.predict(X_test)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "kncf = KNeighborsClassifier()\n",
    "kncf.fit(X_train, y_train)\n",
    "kncf_dt_pred = kncf.predict(X_test)\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "svc = KNeighborsClassifier()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, \n",
    "                                 criterion='entropy', max_features=None,)\n",
    "et_clf = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, \n",
    "                              bootstrap=True, random_state=10, max_samples=1.0)\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, \n",
    "                            max_samples=1.0, bootstrap=False, n_jobs=-1,\n",
    "                            bootstrap_features=True, max_features=0.5, oob_score=False)\n",
    "voting_model = VotingClassifier(estimators=[('RandomForestClassifier', rnd_clf), ('BaggingClassifier', bag_clf),\n",
    "                                            ('ExtraTreesClassifier', et_clf)], voting='soft', n_jobs=-1)\n",
    "voting_model.fit(X, y)\n",
    "voting_model_dt_pred = voting_model.predict(df_test)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "gbc_dt_pred = gbc.predict(X_test)\n",
    "\n",
    "\n",
    "params1 = {'ccp_alpha': 0.011001332269966666,\n",
    "         'learning_rate': 0.1,\n",
    "         'loss': 'exponential',\n",
    "         'max_depth': 8,\n",
    "         'max_features': 'log2',\n",
    "         'min_impurity_decrease': 0.8671820004771132,\n",
    "         'min_samples_leaf': 28,\n",
    "         'min_samples_split': 0.32582763423323347,\n",
    "         'n_estimators': 300}\n",
    "\n",
    "gbc = GradientBoostingClassifier(**params1)\n",
    "gbc.fit(X_train, y_train)\n",
    "gbc_dt_pred2 = gbc.predict(X_test)\n",
    "\n",
    "etsc = ExtraTreesClassifier()\n",
    "etsc.fit(X, y)\n",
    "etsc_dt_pred = etsc.predict(df_test)\n",
    "\n",
    "xgb = XGBClassifier(**xgb_params)\n",
    "xgb.fit(X, y)\n",
    "xgb_clf_pred = xgb.predict(df_test)\n",
    "\n",
    "hgb_clf = HistGradientBoostingClassifier()\n",
    "hgb_clf.fit(X_train, y_train)\n",
    "hgb_clf_pred = hgb_clf.predict(X_test)\n",
    "\n",
    "params2 = {'learning_rate': 0.1,\n",
    "            'loss': 'auto',\n",
    "            'max_bins': 221,\n",
    "            'max_depth': 79,\n",
    "            'max_iter': 206,\n",
    "            'max_leaf_nodes': 9,\n",
    "            'min_samples_leaf': 7,\n",
    "            'random_state': 235,\n",
    "            'validation_fraction': 0.08}\n",
    "\n",
    "hgb_clf = HistGradientBoostingClassifier(**params2)\n",
    "hgb_clf.fit(X_train, y_train)\n",
    "hgb_clf_pred = hgb_clf.predict(X_test)\n",
    "\n",
    "et_clf = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, bootstrap=True, random_state=10, max_samples=1.0)\n",
    "et_clf.fit(X_train, y_train)\n",
    "et_clf_pred = et_clf.predict(X_test)\n",
    "\n",
    "xgb_params={'ccp_alpha': 0.5803345757292036,\n",
    "            'learning_rate': 0.01,\n",
    "            'loss': 'deviance',\n",
    "            'max_depth': 4,\n",
    "            'max_features': 'sqrt',\n",
    "            'min_impurity_decrease': 0.21694403720395206,\n",
    "            'min_samples_leaf': 13,\n",
    "            'min_samples_split': 0.524057300043958,\n",
    "            'n_estimators': 1000}\n",
    "\n",
    "xgb = XGBClassifier(**xgb_params)\n",
    "xgb.fit(X, y)\n",
    "xgb_clf_pred = xgb.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e85687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
