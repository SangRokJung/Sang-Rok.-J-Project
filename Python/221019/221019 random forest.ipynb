{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b6bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn import metrics\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0a2ab10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 데이터 전처리\n",
    "df_t = sns.load_dataset('titanic')\n",
    "\n",
    "# 불필요 컬럼 제거\n",
    "df_t.drop(columns=['class', 'alive', 'embark_town', 'who', 'adult_male', 'alone'], inplace=True)\n",
    "\n",
    "# 연령의 결측치 해결\n",
    "age_md = df_t.groupby(['pclass', 'sex']).age.agg(['median'])\n",
    "df_t.loc[(df_t['sex'] == 'male') & (df_t['pclass'] == 1) & (df_t.age.isna()), \"age\"] = age_md.loc[1, 'male'][0]\n",
    "df_t.loc[(df_t['sex'] == 'male') & (df_t['pclass'] == 2) & (df_t.age.isna()), \"age\"] = age_md.loc[2, 'male'][0]\n",
    "df_t.loc[(df_t['sex'] == 'male') & (df_t['pclass'] == 3) & (df_t.age.isna()), \"age\"] = age_md.loc[3, 'male'][0]\n",
    "df_t.loc[(df_t['sex'] == 'female') & (df_t['pclass'] == 1) & (df_t.age.isna()), \"age\"] = age_md.loc[1, 'female'][0]\n",
    "df_t.loc[(df_t['sex'] == 'female') & (df_t['pclass'] == 2) & (df_t.age.isna()), \"age\"] = age_md.loc[2, 'female'][0]\n",
    "df_t.loc[(df_t['sex'] == 'female') & (df_t['pclass'] == 3) & (df_t.age.isna()), \"age\"] = age_md.loc[3, 'female'][0]\n",
    "\n",
    "# embarked 결측치 해결\n",
    "df_t.embarked.fillna(df_t.embarked.unique()[0], inplace=True)\n",
    "\n",
    "# 연령층 별 컬럼 생성.\n",
    "df_t.loc[df_t.age >= 50, \"age_new\"] = \"old\"\n",
    "df_t.loc[(df_t.age < 50) & (df_t.age>=10), \"age_new\"] = \"young\"\n",
    "df_t.loc[df_t.age < 10, \"age_new\"] = \"baby\"\n",
    "\n",
    "# 인코딩\n",
    "# for column in ['sex', 'embarked', 'age_new'] :\n",
    "#     datas = df_t[column].unique()\n",
    "#     for i, d in enumerate(datas) :\n",
    "#         df_t[column].replace(d, i, inplace=True)\n",
    "\n",
    "# 인코딩\n",
    "og_columns = df_t.columns[(df_t.dtypes=='O')|(df_t.dtypes=='category')|(df_t.dtypes=='bool')]            \n",
    "for i in og_columns :\n",
    "    globals()[f'df1_{i}_encoder'] = LabelEncoder()\n",
    "    globals()[f'df1_{i}_encoder'].fit(df_t[i])\n",
    "    df_t[i] = globals()[f'df1_{i}_encoder'].transform(df_t[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X, Y 분리\n",
    "X = df_t.drop(columns='survived')\n",
    "y = df_t['survived']\n",
    "\n",
    "# test, train 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=12)\n",
    "\n",
    "# np.random.shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=1000) #ccp : 분기점\n",
    "rfc.fit(X_train, y_train)\n",
    "# predict이 필요한 이유 : 정답이 없는 경우가 있기 때문.\n",
    "dt_pred = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "# 새로운 타이타닉 데이터 전처리 \n",
    "\n",
    "df_test = pd.read_csv('./test.csv')\n",
    "\n",
    "# df_test.info()\n",
    "# Name, Sex, Ticket, Cabin, Embarked 해결 필요\n",
    "\n",
    "# 연령의 결측치 해결\n",
    "# fare 결측치 해결\n",
    "age_md = df_test.groupby(['Pclass', 'Sex']).Age.agg(['median'])\n",
    "fare_md = df_test.groupby(['Pclass', 'Sex']).Fare.agg(['median'])\n",
    "for i in ['male', 'female'] : \n",
    "    for y in range(1, 4) : \n",
    "        f\"df_test.loc[(df_test['Sex'] == '{i}') & (df_test['Pclass'] == {y}) & (df_test.Age.isna()), 'Age'] = age_md.loc[{y}, '{i}'][0]\"\n",
    "        f\"df_test.loc[(df_test['Sex'] == '{i}') & (df_test['Pclass'] == {y}) & (df_test.Fare.isna()), 'Fare'] = fare_md.loc[{y}, '{i}'][0]\"\n",
    "        \n",
    "\n",
    "# 결측치가 너무 많은 데이터, 컬럼 삭제\n",
    "df_test.drop(columns=['Cabin'], inplace=True)\n",
    "\n",
    "# age_new 생성\n",
    "df_test.loc[df_test.Age >= 50, \"age_new\"] = \"old\"\n",
    "df_test.loc[(df_test.Age < 50) & (df_test.Age>=10), \"age_new\"] = \"young\"\n",
    "df_test.loc[df_test.Age < 10, \"age_new\"] = \"baby\"\n",
    "\n",
    "# 필요 없는 데이터 제거\n",
    "df_test.drop(columns=['Name', 'Ticket', 'PassengerId', \"SibSp\", \"Parch\", 'Age', 'Embarked'], inplace=True)\n",
    "\n",
    "\n",
    "# 컬럼 소문자로 변경 \n",
    "l1 = []\n",
    "for i in list(df_test.columns):\n",
    "    l1.append(i.lower())\n",
    "df_test.set_axis(l1, axis='columns', inplace=True)\n",
    "\n",
    "# Index(['pclass', 'Sex', 'age', 'fare', 'embarked', 'predict survived'], dtype='object')\n",
    "# Labeling으로 문자형 데이터를 숫자형으로 변환\n",
    "for i in ['sex', 'age_new']:\n",
    "    globals()[f'df_test{i}_encoder'] = LabelEncoder()\n",
    "    globals()[f'df_test{i}_encoder'].fit(df_test[i])\n",
    "    df_test[i] = globals()[f'df_test{i}_encoder'].transform(df_test[i])\n",
    "\n",
    "# fare 결측치 해결    \n",
    "df_test['fare'].fillna(df_test['fare'].mean(), inplace=True)\n",
    "# df_test[df_test['fare'].isna() == True] \n",
    "\n",
    "# 학습 데이터 70%, 테스트 데이터 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d9f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### orginal data ###\n",
    "df_train = pd.read_csv(\"./titanic/train.csv\")\n",
    "\n",
    "df_train.drop(columns=[\"Name\", \"Ticket\", \"Embarked\", \"PassengerId\", \"Cabin\"], inplace=True)\n",
    "\n",
    "# age_new 컬럼 생성.\n",
    "df_train.loc[df_train.Age >= 50, \"age_new\"] = \"old\"\n",
    "df_train.loc[(df_train.Age < 50) & (df_train.Age>=10), \"age_new\"] = \"young\"\n",
    "df_train.loc[df_train.Age < 10, \"age_new\"] = \"baby\"\n",
    "\n",
    "# 인코딩\n",
    "og_columns = df_train.columns[(df_train.dtypes=='O')|(df_train.dtypes=='category')|(df_train.dtypes=='bool')]\n",
    "for i in og_columns : \n",
    "    globals()[f'df_train_{i}_encoder'] = LabelEncoder()\n",
    "    globals()[f'df_train_{i}_encoder'].fit(df_train[i])\n",
    "    df_train[i] = globals()[f'df_train_{i}_encoder'].transform(df_train[i])\n",
    "    \n",
    "# 연령의 결측치 해결\n",
    "Age_md = df_train.groupby(['Pclass', 'Sex']).Age.agg(['median'])\n",
    "df_train.loc[(df_train['Sex'] ==  0) & (df_train['Pclass'] == 1) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[1, 0][0]\n",
    "df_train.loc[(df_train['Sex'] == 0) & (df_train['Pclass'] == 2) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[2, 0][0]\n",
    "df_train.loc[(df_train['Sex'] == 0) & (df_train['Pclass'] == 3) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[3, 0][0]\n",
    "df_train.loc[(df_train['Sex'] == 1) & (df_train['Pclass'] == 1) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[1, 1][0]\n",
    "df_train.loc[(df_train['Sex'] == 1) & (df_train['Pclass'] == 2) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[2, 1][0]\n",
    "df_train.loc[(df_train['Sex'] == 1) & (df_train['Pclass'] == 3) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[3, 1][0]\n",
    "\n",
    "df_train[\"family\"] = df_train.SibSp + df_train.Parch\n",
    "df_train.drop(columns=[\"SibSp\", \"Parch\"], inplace=True)\n",
    "\n",
    "# X, Y , test, train 분리\n",
    "X = df_train.drop(columns='Survived')\n",
    "y = df_train['Survived']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=19)\n",
    "\n",
    "\n",
    "# 새로운 타이타닉 데이터 전처리 \n",
    "df_test = pd.read_csv('./test.csv')\n",
    "\n",
    "df_test.drop(columns=[\"Name\", \"Ticket\", \"Embarked\", \"PassengerId\", \"Cabin\"], inplace=True)\n",
    "\n",
    "# 연령의 결측치 해결\n",
    "# fare 결측치 해결\n",
    "age_md = df_test.groupby(['Pclass', 'Sex']).Age.agg(['mean'])\n",
    "df_test.loc[(df_test['Sex'] == 'male') & (df_test['Pclass'] == 1) & (df_test.Age.isna()), 'Age'] = age_md.loc[1, 'male'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'male') & (df_test['Pclass'] == 2) & (df_test.Age.isna()), 'Age'] = age_md.loc[2, 'male'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'male') & (df_test['Pclass'] == 3) & (df_test.Age.isna()), 'Age'] = age_md.loc[3, 'male'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'female') & (df_test['Pclass'] == 1) & (df_test.Age.isna()), 'Age'] = age_md.loc[1, 'female'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'female') & (df_test['Pclass'] == 2) & (df_test.Age.isna()), 'Age'] = age_md.loc[2, 'female'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'female') & (df_test['Pclass'] == 3) & (df_test.Age.isna()), 'Age'] = age_md.loc[3, 'female'][0]\n",
    "df_test.Fare.fillna(df_test[\"Fare\"].mean(), inplace=True)\n",
    "\n",
    "# age_new 생성\n",
    "df_test.loc[df_test.Age >= 50, \"age_new\"] = \"old\"\n",
    "df_test.loc[(df_test.Age < 50) & (df_test.Age>=10), \"age_new\"] = \"young\"\n",
    "df_test.loc[df_test.Age < 10, \"age_new\"] = \"baby\"\n",
    "\n",
    "df_test[\"family\"] = df_test.SibSp + df_test.Parch\n",
    "df_test.drop(columns=[\"SibSp\", \"Parch\"], inplace=True)\n",
    "\n",
    "og_columns = df_test.columns[(df_test.dtypes=='O')|(df_test.dtypes=='category')|(df_test.dtypes=='bool')]\n",
    "for i in og_columns : \n",
    "    globals()[f'df_test{i}_encoder'] = LabelEncoder()\n",
    "    globals()[f'df_test{i}_encoder'].fit(df_test[i])\n",
    "    df_test[i] = globals()[f'df_test{i}_encoder'].transform(df_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 타이타닉 데이터 생존 여부 예측\n",
    "pred_result = rfc.predict(df_test)\n",
    "pred_result_2 =  df_tsurvived_encoder.inverse_transform(pred_result)\n",
    "df_test['survived'] = pred_result_2\n",
    "\n",
    "# 파일 저장\n",
    "tit = pd.read_csv('./test.csv')\n",
    "tit.drop(list(tit.columns)[1:], axis = 1, inplace=True)\n",
    "tit['Survived'] = df_test['survived']\n",
    "tit.set_index('PassengerId', inplace=True)\n",
    "tit.to_csv('tit_test_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "078a5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nRandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=10000, n_jobs=-1) #ccp : 분기점\n",
    "rfc.fit(X_train, y_train)\n",
    "dt_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2349e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtclf = DecisionTreeClassifier(max_depth=5) #ccp : 분기점\n",
    "dtclf.fit(X_train, y_train)\n",
    "dt_pred = dtclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08645ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44 11]\n",
      " [13 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79        55\n",
      "           1       0.67      0.63      0.65        35\n",
      "\n",
      "    accuracy                           0.73        90\n",
      "   macro avg       0.72      0.71      0.72        90\n",
      "weighted avg       0.73      0.73      0.73        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_hat = knn.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "knn_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(knn_matrix)\n",
    "\n",
    "knn_report = metrics.classification_report(y_test, y_hat)\n",
    "print(knn_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3047ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred) :\n",
    "    print(\"-\" * 5)\n",
    "    print(\"오차 행렬\\n\",confusion_matrix(y_test, pred))\n",
    "    print(\"정확도(accuracy) : %.2f\" %accuracy_score(y_test, pred))\n",
    "    print(\"정밀도(precision) : %.2f\" %precision_score(y_test, pred))\n",
    "    print(\"재현율(recall) : %.2f\" %recall_score(y_test, pred))\n",
    "    print(\"f1 Score : %.2f\" %f1_score(y_test, pred))\n",
    "    print(\"AUC : %.2f\" % roc_auc_score(y_test, pred))\n",
    "    print(\"-\" * 5)\n",
    "    return accuracy_score(y_test, pred), precision_score(y_test, pred),recall_score(y_test, pred), f1_score(y_test, pred), roc_auc_score(y_test, pred) \n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "def get_eval_by_threshold(y_test, pred_proba):\n",
    "    ts_accuracy = []\n",
    "    ts_precision = []\n",
    "    ts_recall = []\n",
    "    ts_datas = {}\n",
    "    f1_list = []\n",
    "    auc_list= []\n",
    "    for custom_threshold in range(1, 11) :\n",
    "        tt_binarizer = Binarizer(threshold=custom_threshold * 0.1)\n",
    "        custom_predict = tt_binarizer.fit_transform(pred_proba)[:, 1]\n",
    "        accuracy  = accuracy_score(y_test, custom_predict)\n",
    "        recall    = recall_score(y_test, custom_predict)\n",
    "        precision = precision_score(y_test, custom_predict)\n",
    "        f1 = f1_score(y_test, custom_predict)\n",
    "        auc = roc_auc_score(y_test, custom_predict)\n",
    "        \n",
    "        ts_accuracy.append(accuracy)\n",
    "        ts_precision.append(precision)\n",
    "        ts_recall.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        auc_list.append(auc)\n",
    "        \n",
    "    ts_datas['thresholds'] = [i * 0.1 for i in range(1, 11)]\n",
    "    ts_datas['accuracy'] = ts_accuracy\n",
    "    ts_datas['precision'] = ts_precision\n",
    "    ts_datas['recall'] = ts_recall\n",
    "    ts_datas['f1_score'] = f1_list\n",
    "    ts_datas['auc'] = auc_list\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    pd.DataFrame(ts_datas).set_index('thresholds').plot()\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d648a629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtclf = DecisionTreeClassifier() # option : max_depth=4, ccp_alpha=0.01\n",
    "dtclf.fit(X_train, y_train)\n",
    "pred_proba = dtclf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d78200c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  5]\n",
      " [25 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.91      0.77        55\n",
      "           1       0.67      0.29      0.40        35\n",
      "\n",
      "    accuracy                           0.67        90\n",
      "   macro avg       0.67      0.60      0.58        90\n",
      "weighted avg       0.67      0.67      0.63        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "svm_clf = SVC(kernel = 'rbf')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_hat = svm_clf.predict(X_test)\n",
    "\n",
    "svm_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(svm_matrix)\n",
    "\n",
    "svm_report = metrics.classification_report(y_test, y_hat)\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "47897e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier\n",
      "-----\n",
      "오차 행렬\n",
      " [[50  5]\n",
      " [11 24]]\n",
      "정확도(accuracy) : 0.82\n",
      "정밀도(precision) : 0.83\n",
      "재현율(recall) : 0.69\n",
      "f1 Score : 0.75\n",
      "AUC : 0.80\n",
      "-----\n",
      "\n",
      "RandomForestClassifier(n_estimators=10000, n_jobs=-1) \n",
      "-----\n",
      "오차 행렬\n",
      " [[49  6]\n",
      " [ 9 26]]\n",
      "정확도(accuracy) : 0.83\n",
      "정밀도(precision) : 0.81\n",
      "재현율(recall) : 0.74\n",
      "f1 Score : 0.78\n",
      "AUC : 0.82\n",
      "-----\n",
      "\n",
      "RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, criterion='entropy', max_features=None,)\n",
      "-----\n",
      "오차 행렬\n",
      " [[50  5]\n",
      " [10 25]]\n",
      "정확도(accuracy) : 0.83\n",
      "정밀도(precision) : 0.83\n",
      "재현율(recall) : 0.71\n",
      "f1 Score : 0.77\n",
      "AUC : 0.81\n",
      "-----\n",
      "\n",
      "ExtraTreesClassifier\n",
      "-----\n",
      "오차 행렬\n",
      " [[48  7]\n",
      " [ 7 28]]\n",
      "정확도(accuracy) : 0.84\n",
      "정밀도(precision) : 0.80\n",
      "재현율(recall) : 0.80\n",
      "f1 Score : 0.80\n",
      "AUC : 0.84\n",
      "-----\n",
      "\n",
      "ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, bootstrap=True, random_state=10, max_samples=1.0)\n",
      "-----\n",
      "오차 행렬\n",
      " [[48  7]\n",
      " [ 9 26]]\n",
      "정확도(accuracy) : 0.82\n",
      "정밀도(precision) : 0.79\n",
      "재현율(recall) : 0.74\n",
      "f1 Score : 0.76\n",
      "AUC : 0.81\n",
      "-----\n",
      "\n",
      "DecisionTreeClassifier(max_depth=5)\n",
      "-----\n",
      "오차 행렬\n",
      " [[47  8]\n",
      " [10 25]]\n",
      "정확도(accuracy) : 0.80\n",
      "정밀도(precision) : 0.76\n",
      "재현율(recall) : 0.71\n",
      "f1 Score : 0.74\n",
      "AUC : 0.78\n",
      "-----\n",
      "\n",
      "BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, max_samples=1.0, bootstrap=False, n_jobs=-1, bootstrap_features=True, max_features=0.5, oob_score=False)\n",
      "-----\n",
      "오차 행렬\n",
      " [[50  5]\n",
      " [13 22]]\n",
      "정확도(accuracy) : 0.80\n",
      "정밀도(precision) : 0.81\n",
      "재현율(recall) : 0.63\n",
      "f1 Score : 0.71\n",
      "AUC : 0.77\n",
      "-----\n",
      "\n",
      "DecisionTreeClassifier\n",
      "-----\n",
      "오차 행렬\n",
      " [[45 10]\n",
      " [ 8 27]]\n",
      "정확도(accuracy) : 0.80\n",
      "정밀도(precision) : 0.73\n",
      "재현율(recall) : 0.77\n",
      "f1 Score : 0.75\n",
      "AUC : 0.79\n",
      "-----\n",
      "\n",
      "ExtraTreeClassifier\n",
      "-----\n",
      "오차 행렬\n",
      " [[47  8]\n",
      " [ 9 26]]\n",
      "정확도(accuracy) : 0.81\n",
      "정밀도(precision) : 0.76\n",
      "재현율(recall) : 0.74\n",
      "f1 Score : 0.75\n",
      "AUC : 0.80\n",
      "-----\n",
      "\n",
      "KNeighborsClassifier\n",
      "-----\n",
      "오차 행렬\n",
      " [[45 10]\n",
      " [14 21]]\n",
      "정확도(accuracy) : 0.73\n",
      "정밀도(precision) : 0.68\n",
      "재현율(recall) : 0.60\n",
      "f1 Score : 0.64\n",
      "AUC : 0.71\n",
      "-----\n",
      "\n",
      "SVC\n",
      "-----\n",
      "오차 행렬\n",
      " [[45 10]\n",
      " [14 21]]\n",
      "정확도(accuracy) : 0.73\n",
      "정밀도(precision) : 0.68\n",
      "재현율(recall) : 0.60\n",
      "f1 Score : 0.64\n",
      "AUC : 0.71\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7333333333333333,\n",
       " 0.6774193548387096,\n",
       " 0.6,\n",
       " 0.6363636363636364,\n",
       " 0.7090909090909091)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"VotingClassifier\")\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_model = VotingClassifier(estimators=[('RandomForestClassifier', rnd_clf), ('BaggingClassifier', bag_clf),\n",
    "                                            ('ExtraTreesClassifier', et_clf)], voting='soft', n_jobs=-1)\n",
    "voting_model.fit(X_train, y_train)\n",
    "voting_model_dt_pred = voting_model.predict(X_test)\n",
    "get_clf_eval(y_test, voting_model_dt_pred)\n",
    "\n",
    "\n",
    "print(\"\\nRandomForestClassifier(n_estimators=10000, n_jobs=-1) \")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=10000, n_jobs=-1) \n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_dt_pred = rfc.predict(X_test)\n",
    "get_clf_eval(y_test, rfc_dt_pred)\n",
    "\n",
    "print(\"\\nRandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, criterion='entropy', max_features=None,)\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, \n",
    "                                 criterion='entropy', max_features=None,)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "rnd_clf_dt_pred = rnd_clf.predict(X_test)\n",
    "get_clf_eval(y_test, rnd_clf_dt_pred)\n",
    "\n",
    "\n",
    "print(\"\\nExtraTreesClassifier\")\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etsc = ExtraTreesClassifier()\n",
    "etsc.fit(X_train, y_train)\n",
    "etsc_dt_pred = etsc.predict(X_test)\n",
    "get_clf_eval(y_test, etsc_dt_pred)\n",
    "\n",
    "\n",
    "print(\"\\nExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, bootstrap=True, random_state=10, max_samples=1.0)\")\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "et_clf = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, \n",
    "                              bootstrap=True, random_state=10, max_samples=1.0)\n",
    "et_clf.fit(X_train, y_train)\n",
    "et_clf_dt_pred = et_clf.predict(X_test)\n",
    "get_clf_eval(y_test, et_clf_dt_pred)\n",
    "\n",
    "\n",
    "print(\"\\nDecisionTreeClassifier(max_depth=5)\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtclf = DecisionTreeClassifier(max_depth=5) \n",
    "dtclf.fit(X_train, y_train)\n",
    "dtclf_dt_pred = dtclf.predict(X_test)\n",
    "get_clf_eval(y_test, dtclf_dt_pred)\n",
    "\n",
    "print(\"\\nBaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, max_samples=1.0, bootstrap=False, n_jobs=-1, bootstrap_features=True, max_features=0.5, oob_score=False)\")\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, \n",
    "                            max_samples=1.0, bootstrap=False, n_jobs=-1,\n",
    "                            bootstrap_features=True, max_features=0.5, oob_score=False)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf_dt_pred = bag_clf.predict(X_test)\n",
    "get_clf_eval(y_test, bag_clf_dt_pred)\n",
    "\n",
    "print(\"\\nDecisionTreeClassifier\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtclf = DecisionTreeClassifier() \n",
    "dtclf.fit(X_train, y_train)\n",
    "dtclf_dt_pred = dtclf.predict(X_test)\n",
    "get_clf_eval(y_test, dtclf_dt_pred)\n",
    "\n",
    "print(\"\\nExtraTreeClassifier\")\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "etc = ExtraTreeClassifier() \n",
    "etc.fit(X_train, y_train)\n",
    "etc_dt_pred = etc.predict(X_test)\n",
    "get_clf_eval(y_test, etc_dt_pred)\n",
    "\n",
    "print(\"\\nKNeighborsClassifier\")\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "kncf = KNeighborsClassifier()\n",
    "kncf.fit(X_train, y_train)\n",
    "kncf_dt_pred = kncf.predict(X_test)\n",
    "get_clf_eval(y_test, kncf_dt_pred)\n",
    "\n",
    "print(\"\\nSVC\")\n",
    "from sklearn.svm import SVC \n",
    "svc = KNeighborsClassifier()\n",
    "svc.fit(X_train, y_train)\n",
    "svc_dt_pred = svc.predict(X_test)\n",
    "get_clf_eval(y_test, svc_dt_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e23363c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etsc = ExtraTreesClassifier()\n",
    "etsc.fit(X, y)\n",
    "etsc_dt_pred = etsc.predict(df_test)\n",
    "df_test['survived'] = etsc_dt_pred\n",
    "\n",
    "# 파일 저장\n",
    "tit = pd.read_csv('./test.csv')\n",
    "tit.drop(list(tit.columns)[1:], axis = 1, inplace=True)\n",
    "tit['Survived'] = df_test['survived']\n",
    "tit.set_index('PassengerId', inplace=True)\n",
    "tit.to_csv('tit_test_etsc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11947526",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, \n",
    "                                 criterion='entropy', max_features=None,)\n",
    "et_clf = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, \n",
    "                              bootstrap=True, random_state=10, max_samples=1.0)\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, \n",
    "                            max_samples=1.0, bootstrap=False, n_jobs=-1,\n",
    "                            bootstrap_features=True, max_features=0.5, oob_score=False)\n",
    "voting_model = VotingClassifier(estimators=[('RandomForestClassifier', rnd_clf), ('BaggingClassifier', bag_clf),\n",
    "                                            ('ExtraTreesClassifier', et_clf)], voting='soft', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a57d801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting kaggle\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_model = VotingClassifier(estimators=[('RandomForestClassifier', rnd_clf), ('BaggingClassifier', bag_clf),\n",
    "                                            ('ExtraTreesClassifier', et_clf)], voting='soft', n_jobs=-1)\n",
    "voting_model.fit(X, y)\n",
    "voting_model_dt_pred = voting_model.predict(df_test)\n",
    "df_test['survived'] = voting_model_dt_pred\n",
    "\n",
    "# 파일 저장\n",
    "tit = pd.read_csv('./test.csv')\n",
    "tit.drop(list(tit.columns)[1:], axis = 1, inplace=True)\n",
    "tit['Survived'] = df_test['survived']\n",
    "tit.set_index('PassengerId', inplace=True)\n",
    "tit.to_csv('tit_test_voting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5e40c2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>age_new</th>\n",
       "      <th>family</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24.525104</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24.525104</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24.525104</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age      Fare  age_new  family  survived\n",
       "0         3    1  34.500000    7.8292        2       0         0\n",
       "1         3    0  47.000000    7.0000        2       1         0\n",
       "2         2    1  62.000000    9.6875        1       0         1\n",
       "3         3    1  27.000000    8.6625        2       0         0\n",
       "4         3    0  22.000000   12.2875        2       2         1\n",
       "..      ...  ...        ...       ...      ...     ...       ...\n",
       "413       3    1  24.525104    8.0500        2       0         0\n",
       "414       1    0  39.000000  108.9000        2       0         1\n",
       "415       3    1  38.500000    7.2500        2       0         0\n",
       "416       3    1  24.525104    8.0500        2       0         0\n",
       "417       3    1  24.525104   22.3583        2       2         0\n",
       "\n",
       "[418 rows x 7 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "678ab512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "-----\n",
      "오차 행렬\n",
      " [[49  6]\n",
      " [10 25]]\n",
      "정확도(accuracy) : 0.82\n",
      "정밀도(precision) : 0.81\n",
      "재현율(recall) : 0.71\n",
      "f1 Score : 0.76\n",
      "AUC : 0.80\n",
      "-----\n",
      "\n",
      "최적 하이퍼 파라미터:\n",
      " {'learning_rate': 0.09, 'n_estimators': 131}\n",
      "최고 예측 정확도: 0.8390\n",
      "\n",
      "-----\n",
      "오차 행렬\n",
      " [[49  6]\n",
      " [10 25]]\n",
      "정확도(accuracy) : 0.82\n",
      "정밀도(precision) : 0.81\n",
      "재현율(recall) : 0.71\n",
      "f1 Score : 0.76\n",
      "AUC : 0.80\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8222222222222222,\n",
       " 0.8064516129032258,\n",
       " 0.7142857142857143,\n",
       " 0.7575757575757576,\n",
       " 0.8025974025974026)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "GBM은 경사 하강법(Gradient Descent)를 이용해 가중치 업데이트를 수행하는 기법이다. \n",
    "GBM이 일반적으로 랜덤포레스트보다 성능이 뛰어나기는 하지만, 수행 시간이 오래 걸린다는 단점이 있다.\n",
    "\n",
    "loss : 경사 하강법에서 사용할 비용함수 지정 (디폴트는 deviance)\n",
    "learning_rate : 약한 학습기가 순차적으로 오류 값을 보정해 나가는 데 적용하는 계수로 0 ~ 1 값 지정 가능 (디폴트는 0.1)\n",
    "너무 작은 값 지정 -> 예측 성능은 높아질 수 있지만 수행 시간이 오래 걸릴 수 있고, 반복이 완료되어도 최소오류값을 찾지 못할 수 있음\n",
    "너무 큰 값 지정 -> 빠른 수행은 가능하지만 최소오류값을 못찾고 지나쳐 예측 성능이 저하될 수 있음\n",
    "n_estimators : 약한 학습기의 개수 (디폴트는 100)\n",
    "개수가 많을수록 예측 성능은 높아질 수 있지만 수행 시간이 오래 걸림\n",
    "subsample : 학습에 사용하는 데이터의 샘플링 비율로 0 ~ 1 값 지정 가능 (디폴트는 1, 즉 전체 학습 데이터 기반)\n",
    "'''\n",
    "\n",
    "print(\"GradientBoostingClassifier\")\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "gbc_dt_pred = gbc.predict(X_test)\n",
    "get_clf_eval(y_test, gbc_dt_pred)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'n_estimators' : [i for i in range(100, 200)], 'learning_rate' : [i * 0.01 for i in range(5, 10)]}\n",
    "grid_cv = GridSearchCV(gbc, param_grid=params)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "gcv = grid_cv.best_params_\n",
    "print('\\n최적 하이퍼 파라미터:\\n', gcv)\n",
    "print('최고 예측 정확도: {0:.4f}\\n'.format(grid_cv.best_score_))\n",
    "\n",
    "new_pred = grid_cv.best_estimator_.predict(X_test)\n",
    "get_clf_eval(y_test, new_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf865465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "오차 행렬\n",
      " [[57  2]\n",
      " [10 21]]\n",
      "정확도(accuracy) : 0.87\n",
      "정밀도(precision) : 0.91\n",
      "재현율(recall) : 0.68\n",
      "f1 Score : 0.78\n",
      "AUC : 0.82\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8666666666666667,\n",
       " 0.9130434782608695,\n",
       " 0.6774193548387096,\n",
       " 0.7777777777777777,\n",
       " 0.8217605248769819)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'ccp_alpha': 0.011001332269966666,\n",
    "         'learning_rate': 0.1,\n",
    "         'loss': 'exponential',\n",
    "         'max_depth': 8,\n",
    "         'max_features': 'log2',\n",
    "         'min_impurity_decrease': 0.8671820004771132,\n",
    "         'min_samples_leaf': 28,\n",
    "         'min_samples_split': 0.32582763423323347,\n",
    "         'n_estimators': 300}\n",
    "\n",
    "gbc = GradientBoostingClassifier(**param)\n",
    "gbc.fit(X_train, y_train)\n",
    "gbc_dt_pred = gbc.predict(X_test)\n",
    "get_clf_eval(y_test, gbc_dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d1160504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm 교차검증: 0.818\n",
      "gbm 예측점수: 0.9\n"
     ]
    }
   ],
   "source": [
    "gbm_clf = GradientBoostingClassifier()\n",
    "\n",
    "gbm_results = cross_val_score(gbm_clf, X_train, y_train, scoring='accuracy', cv=10, n_jobs=4)\n",
    "print('gbm 교차검증:', round(np.mean(gbm_results), 3))\n",
    "\n",
    "gbm_clf.fit(X_train, y_train)\n",
    "print('gbm 예측점수:', round(np.mean(gbm_clf.score(X_test, y_test)), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1e26d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████| 500/500 [01:47<00:00,  4.67trial/s, best loss: -0.8777777777777778]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "\n",
    "def gbm_objective(search_space):\n",
    "    model = GradientBoostingClassifier(**search_space)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "\n",
    "# new search space\n",
    "search_space={'loss':hp.choice('loss', ['deviance', 'exponential']),\n",
    "              'max_depth':hp.choice('max_depth', range(2, 10)),\n",
    "              'min_samples_split':hp.uniform('min_samples_split', 0.1, 1),\n",
    "              'min_samples_leaf':hp.choice('min_samples_leaf', range(1, 30)),\n",
    "              'max_features':hp.choice('max_features', [None, 'sqrt', 'log2']),\n",
    "              'min_impurity_decrease':hp.uniform('min_impurity_decrease', 0.1, 1),\n",
    "              'ccp_alpha':hp.uniform('ccp_alpha', 0.01, 1),\n",
    "              'learning_rate':hp.choice('learning_rate', [0.1, 0.01]),\n",
    "              'n_estimators':hp.choice('n_estimators', [100, 200, 300, 400, 500,1000])}\n",
    "\n",
    "# set the hyperparam tuning algorithm\n",
    "algorithm=tpe.suggest\n",
    "# implement Hyperopt\n",
    "best_params = fmin(fn=gbm_objective,\n",
    "                   space=search_space,\n",
    "                   algo=algorithm,\n",
    "                   max_evals=500)\n",
    "\n",
    "params1 = space_eval(search_space, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c92412d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [90, 418]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m best_gbm_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      3\u001b[0m best_gbm_clf_pred \u001b[38;5;241m=\u001b[39m best_gbm_clf\u001b[38;5;241m.\u001b[39mpredict(df_test)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mget_clf_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_gbm_clf_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mget_clf_eval\u001b[0;34m(y_test, pred)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_clf_eval\u001b[39m(y_test, pred) :\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m오차 행렬\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m정확도(accuracy) : \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39maccuracy_score(y_test, pred))\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m정밀도(precision) : \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39mprecision_score(y_test, pred))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:307\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[1;32m    223\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    224\u001b[0m ):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    335\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [90, 418]"
     ]
    }
   ],
   "source": [
    "best_gbm_clf = GradientBoostingClassifier(**params1)\n",
    "best_gbm_clf.fit(X_train, y_train)\n",
    "best_gbm_clf_pred = best_gbm_clf.predict(df_test)\n",
    "get_clf_eval(y_test, best_gbm_clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e28084",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbm_clf.fit(X_train, y_train)\n",
    "kg_upload = df_kg.copy()\n",
    "kg_upload['Survived'] = best_gbm_clf.predict(df_kg)\n",
    "kg_upload.Survived.to_csv('./kaggle_upload_boosting2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b7f8e01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/werther/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - py-xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB  anaconda\n",
      "    ca-certificates-2022.4.26  |       hecd8cb5_0         132 KB  anaconda\n",
      "    certifi-2022.6.15          |   py39hecd8cb5_0         157 KB  anaconda\n",
      "    libxgboost-1.5.0           |       he9d5cce_1         2.2 MB  anaconda\n",
      "    openssl-1.1.1o             |       hca72f7f_0         3.5 MB  anaconda\n",
      "    py-xgboost-1.5.0           |   py39hecd8cb5_1         164 KB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         6.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  anaconda/osx-64::_py-xgboost-mutex-2.0-cpu_0 None\n",
      "  libxgboost         anaconda/osx-64::libxgboost-1.5.0-he9d5cce_1 None\n",
      "  py-xgboost         anaconda/osx-64::py-xgboost-1.5.0-py39hecd8cb5_1 None\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2022.07.19~ --> anaconda::ca-certificates-2022.4.26-hecd8cb5_0 None\n",
      "  certifi            pkgs/main::certifi-2022.9.14-py39hecd~ --> anaconda::certifi-2022.6.15-py39hecd8cb5_0 None\n",
      "  openssl              pkgs/main::openssl-1.1.1q-hca72f7f_0 --> anaconda::openssl-1.1.1o-hca72f7f_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libxgboost-1.5.0     | 2.2 MB    | ##################################### | 100% \n",
      "openssl-1.1.1o       | 3.5 MB    | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "py-xgboost-1.5.0     | 164 KB    | ##################################### | 100% \n",
      "ca-certificates-2022 | 132 KB    | ##################################### | 100% \n",
      "certifi-2022.6.15    | 157 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "conda install -c anaconda py-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a66a7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee45aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58efc3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5bb3a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "[17:52:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:52:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-----\n",
      "오차 행렬\n",
      " [[57  2]\n",
      " [ 7 24]]\n",
      "정확도(accuracy) : 0.90\n",
      "정밀도(precision) : 0.92\n",
      "재현율(recall) : 0.77\n",
      "f1 Score : 0.84\n",
      "AUC : 0.87\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9,\n",
       " 0.9230769230769231,\n",
       " 0.7741935483870968,\n",
       " 0.8421052631578947,\n",
       " 0.8701476216511754)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"XGBClassifier\")\n",
    "xgb = XGBClassifier(**params1)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_dt_pred = xgb.predict(X_test)\n",
    "get_clf_eval(y_test, xgb_dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db6e9afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:10] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:53] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:53] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:48:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:10] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:53] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:49:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:10] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:10] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:40] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:42] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:44] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:50] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:51] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:52] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:53] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:53] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:50:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:56] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:50:59] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:50:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:51:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:01] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:02] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:03] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:51:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:08] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:51:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:09] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:10] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:51:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:20] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:51:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:51:24] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:26] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:51:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:32] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:51:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:37] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:39] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"ccp_alpha\", \"loss\", \"max_features\", \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:51:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|█████████████████████| 500/500 [03:36<00:00,  2.31trial/s, best loss: -0.9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "\n",
    "def gbm_objective(search_space):\n",
    "    model = XGBClassifier(**search_space)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "\n",
    "# new search space\n",
    "search_space={'loss':hp.choice('loss', ['deviance', 'exponential']),\n",
    "              'max_depth':hp.choice('max_depth', range(2, 10)),\n",
    "              'min_samples_split':hp.uniform('min_samples_split', 0.1, 1),\n",
    "              'min_samples_leaf':hp.choice('min_samples_leaf', range(1, 30)),\n",
    "              'max_features':hp.choice('max_features', [None, 'sqrt', 'log2']),\n",
    "              'min_impurity_decrease':hp.uniform('min_impurity_decrease', 0.1, 1),\n",
    "              'ccp_alpha':hp.uniform('ccp_alpha', 0.01, 1),\n",
    "              'learning_rate':hp.choice('learning_rate', [0.1, 0.01]),\n",
    "              'n_estimators':hp.choice('n_estimators', [100, 200, 300, 400, 500,1000])}\n",
    "\n",
    "# set the hyperparam tuning algorithm\n",
    "algorithm=tpe.suggest\n",
    "# implement Hyperopt\n",
    "best_params = fmin(fn=gbm_objective,\n",
    "                   space=search_space,\n",
    "                   algo=algorithm,\n",
    "                   max_evals=500)\n",
    "\n",
    "params1 = space_eval(search_space, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeca5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
